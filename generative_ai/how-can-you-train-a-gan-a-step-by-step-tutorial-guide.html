
    
            <!DOCTYPE html>
        <html lang="en">

        <head>
            <!-- Google tag (gtag.js) -->
            <script async src="https://www.googletagmanager.com/gtag/js?id=G-TFCQEJR7TD"></script>
            <script>
            window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
            gtag('config', 'G-TFCQEJR7TD');
            </script>
            <meta charset="utf-8">
            <meta http-equiv="X-UA-Compatible" content="IE=edge">
            <meta name="viewport" content="width=device-width, initial-scale=1.0">
<script type="application/ld+json">
    {
      "@context": "https://schema.org",
      "@type": "WebSite",
      "name": "BestOnlineTutorial",
      "url": "https://www.bestonlinetutorial.com/"
    }
    </script>
            <!-- Common CSS & Icons -->
            <link rel="icon" href="/favicon.ico" type="image/x-icon">
            <link rel="stylesheet" href="/assets/plugins/highlight/styles/monokai-sublime.css">
            <link id="theme-style" rel="stylesheet" href="/assets/css/theme-8.css">
            <link rel="stylesheet" href="/assets/css/post.css">
            <title>How Can You Train a GAN? A Step-by-Step Tutorial Guide</title>
            <meta name="description" content="Learn how to train a GAN with our step-by-step tutorial guide. Unlock the potential of Generative Adversarial Networks today!">
            <script src="https://code.jquery.com/jquery-3.6.0.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>
	        <script src="/assets/js/blog.js"></script>
        </head>

        <body>

            <div id="header-placeholder"></div>

            <div class="main-wrapper">

                <article class="blog-post px-3 py-5 p-md-5">
                    <div class="container single-col-max-width">
                        <header class="blog-post-header">
                            <h1 class="title mb-2">How Can You Train a GAN? A Step-by-Step Tutorial Guide</h1>
                        </header>

                        <div class="blog-post-body">
                            <p>Generative Adversarial Networks (GANs) are a type of machine learning
framework. They use two neural networks. One is the generator and the
other is the discriminator. We train these networks at the same time.
The generator makes fake data. The discriminator checks if the data is
real or fake. Over time, both models get better. This method is popular
in many areas like making images, creating videos, and improving data.
So, GANs are very important in the world of generative AI.</p>
<p>In this article, we will look at a simple step-by-step guide on how
to train a GAN. First, we will learn the basics of GANs. Then, we will
set up the right environment and pick the best framework for training.
We will talk about preparing datasets. We will also design the generator
and discriminator models. We will explain how to check progress and
adjust hyperparameters while training. Additionally, we will give
examples of GAN training with code. We will also mention common problems
we might face and how we can solve them. Here are the main topics we
will cover:</p>
<ul>
<li>How to Effectively Train a GAN Step by Step Tutorial Guide</li>
<li>Understanding the Basics of GANs for Training</li>
<li>Setting Up Your Environment to Train a GAN</li>
<li>Choosing the Right Framework for GAN Training</li>
<li>Preparing Your Dataset for GAN Training</li>
<li>Designing the Generator and Discriminator Models for GAN
Training</li>
<li>Training the GAN: How to Monitor Progress and Tune
Hyperparameters</li>
<li>Practical Examples of Training a GAN with Code</li>
<li>Common Challenges When Training a GAN and How to Overcome Them</li>
<li>Frequently Asked Questions</li>
</ul>
<p>For more information about Generative AI, we can check <a
href="https://bestonlinetutorial.com/generative_ai/what-is-generative-ai-and-how-does-it-work-a-comprehensive-guide.html">what
is generative AI and how does it work</a> and <a
href="https://bestonlinetutorial.com/generative_ai/what-are-the-key-differences-between-generative-and-discriminative-models-understanding-their-unique-features-and-applications.html">the
key differences between generative and discriminative models</a>.</p>
<h2 id="understanding-the-basics-of-gans-for-training">Understanding the
Basics of GANs for Training</h2>
<p>Generative Adversarial Networks or GANs have two parts. They are the
Generator and the Discriminator. These two parts work against each
other.</p>
<ul>
<li><p><strong>Generator</strong>: This part makes new data. It takes
random noise and creates data that looks like the training
data.</p></li>
<li><p><strong>Discriminator</strong>: This part checks if the data is
real or fake. It looks at real data from the training set and fake data
from the Generator. Then it gives a score to show if the data is real or
fake.</p></li>
</ul>
<p>The training process has some steps:</p>
<ol type="1">
<li><p><strong>Initialize the networks</strong>: We start by giving
random weights to both the Generator and the Discriminator.</p></li>
<li><p><strong>Training Loop</strong>:</p>
<ul>
<li>First, we generate fake data using the Generator.</li>
<li>Next, we train the Discriminator with both real and fake data.</li>
<li>We then calculate the loss for the Discriminator.</li>
<li>After that, we update the Discriminator’s weights.</li>
<li>We generate new fake data again.</li>
<li>Then we train the Generator to trick the Discriminator.</li>
<li>We calculate the loss for the Generator.</li>
<li>Finally, we update the Generator’s weights.</li>
</ul></li>
<li><p><strong>Loss Functions</strong>:</p>
<ul>
<li>Discriminator Loss: [ L_D = -<em>{x p</em>{data}}[D(x)] - _{z
p_z}[(1 - D(G(z)))] ]</li>
<li>Generator Loss: [ L_G = -_{z p_z}[D(G(z))] ]</li>
</ul></li>
<li><p><strong>Optimization</strong>: We use optimizers like Adam or
RMSprop to change the weights of both parts.</p></li>
<li><p><strong>Training Duration</strong>: We need to watch how it goes.
We train until the Generator makes good quality data which the
Discriminator cannot tell is fake.</p></li>
</ol>
<p>It is very important to keep a balance between the Generator and the
Discriminator. If one becomes too strong, it may cause the training to
not work.</p>
<p>Knowing these basics is very important to train a GAN well. For more
information about generative AI, you can check <a
href="https://bestonlinetutorial.com/generative_ai/what-is-generative-ai-and-how-does-it-work-a-comprehensive-guide.html">this
comprehensive guide</a>.</p>
<h2 id="setting-up-your-environment-to-train-a-gan">Setting Up Your
Environment to Train a GAN</h2>
<p>To train a Generative Adversarial Network (GAN) well, we need a good
environment. Here are the steps to set it up:</p>
<ol type="1">
<li><p><strong>Install Python</strong>: First, we check that we have
Python 3.6 or newer. We can download it from the <a
href="https://www.python.org/downloads/">official Python
website</a>.</p></li>
<li><p><strong>Set Up a Virtual Environment</strong>:</p>
<div class="sourceCode" id="cb1"><pre
class="sourceCode bash"><code class="sourceCode bash"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="ex">python</span> <span class="at">-m</span> venv gan-env</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="bu">source</span> gan-env/bin/activate  <span class="co"># On Windows we use `gan-env\Scripts\activate`</span></span></code></pre></div></li>
<li><p><strong>Install Required Libraries</strong>: Next, we use pip to
get the libraries we need. The main libraries are TensorFlow or PyTorch,
NumPy, and Matplotlib. We run this command:</p>
<div class="sourceCode" id="cb2"><pre
class="sourceCode bash"><code class="sourceCode bash"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="ex">pip</span> install tensorflow numpy matplotlib</span></code></pre></div>
<p>or if we want to use PyTorch:</p>
<div class="sourceCode" id="cb3"><pre
class="sourceCode bash"><code class="sourceCode bash"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="ex">pip</span> install torch torchvision</span></code></pre></div></li>
<li><p><strong>Check CUDA Installation (if using a GPU)</strong>: For
better speed, especially with big models or datasets, we check if we
have CUDA if we use NVIDIA GPUs. We can verify installation like
this:</p>
<div class="sourceCode" id="cb4"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(torch.cuda.is_available())</span></code></pre></div></li>
<li><p><strong>Set Up Jupyter Notebook (Optional)</strong>: If we like
working in a notebook, we can install Jupyter:</p>
<div class="sourceCode" id="cb5"><pre
class="sourceCode bash"><code class="sourceCode bash"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="ex">pip</span> install jupyter</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="ex">jupyter</span> notebook</span></code></pre></div></li>
<li><p><strong>Organize Project Structure</strong>:</p>
<ul>
<li><p>First, we make a folder for our GAN project:</p>
<div class="sourceCode" id="cb6"><pre
class="sourceCode bash"><code class="sourceCode bash"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mkdir</span> gan_project</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="bu">cd</span> gan_project</span></code></pre></div></li>
<li><p>Inside this folder, we create smaller folders for our data,
models, and notebooks.</p></li>
</ul></li>
<li><p><strong>Download Sample Datasets</strong>: Depending on what we
want to do, we download datasets like CIFAR-10 or MNIST for training. We
can use libraries like <code>torchvision</code> or
<code>tensorflow_datasets</code> to load datasets easily.</p></li>
<li><p><strong>Configure IDE</strong>: We can use an IDE like PyCharm,
VSCode, or Jupyter Notebook for writing code. We need to set our IDE to
the virtual environment we made.</p></li>
</ol>
<p>By following these steps, we will have a solid environment ready for
training our GAN. For more information about generative AI, we can check
out <a
href="https://bestonlinetutorial.com/generative_ai/what-is-generative-ai-and-how-does-it-work-a-comprehensive-guide.html">What
is Generative AI and How Does it Work?</a>.</p>
<h2 id="choosing-the-right-framework-for-gan-training">Choosing the
Right Framework for GAN Training</h2>
<p>Choosing the right framework for training Generative Adversarial
Networks (GANs) is very important for good results and easy use. Here
are some common frameworks that we can use for GAN training. We will
look at their features and what to think about.</p>
<h3 id="tensorflowkeras">TensorFlow/Keras</h3>
<ul>
<li><p><strong>Features</strong>:</p>
<ul>
<li>High-level APIs to build models easily</li>
<li>Big community support and lots of documentation</li>
<li>Built-in support for training on multiple machines</li>
</ul></li>
<li><p><strong>Installation</strong>:</p>
<div class="sourceCode" id="cb7"><pre
class="sourceCode bash"><code class="sourceCode bash"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="ex">pip</span> install tensorflow</span></code></pre></div></li>
<li><p><strong>Example Code</strong>:</p>
<div class="sourceCode" id="cb8"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> tensorflow <span class="im">as</span> tf</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow.keras <span class="im">import</span> layers</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Simple GAN model</span></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> build_generator():</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> tf.keras.Sequential()</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>    model.add(layers.Dense(<span class="dv">128</span>, activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>, input_shape<span class="op">=</span>(<span class="dv">100</span>,)))</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>    model.add(layers.Dense(<span class="dv">784</span>, activation<span class="op">=</span><span class="st">&#39;tanh&#39;</span>))</span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> model</span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> build_discriminator():</span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> tf.keras.Sequential()</span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a>    model.add(layers.Dense(<span class="dv">128</span>, activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>, input_shape<span class="op">=</span>(<span class="dv">784</span>,)))</span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a>    model.add(layers.Dense(<span class="dv">1</span>, activation<span class="op">=</span><span class="st">&#39;sigmoid&#39;</span>))</span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> model</span></code></pre></div></li>
</ul>
<h3 id="pytorch">PyTorch</h3>
<ul>
<li><p><strong>Features</strong>:</p>
<ul>
<li>Dynamic computation graph gives us more flexibility</li>
<li>Easy to understand and debug</li>
<li>Strong support for using GPUs</li>
</ul></li>
<li><p><strong>Installation</strong>:</p>
<div class="sourceCode" id="cb9"><pre
class="sourceCode bash"><code class="sourceCode bash"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="ex">pip</span> install torch torchvision</span></code></pre></div></li>
<li><p><strong>Example Code</strong>:</p>
<div class="sourceCode" id="cb10"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Generator(nn.Module):</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>(Generator, <span class="va">self</span>).<span class="fu">__init__</span>()</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.model <span class="op">=</span> nn.Sequential(</span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>            nn.Linear(<span class="dv">100</span>, <span class="dv">128</span>),</span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>            nn.ReLU(),</span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a>            nn.Linear(<span class="dv">128</span>, <span class="dv">784</span>),</span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a>            nn.Tanh()</span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, z):</span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.model(z)</span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-17"><a href="#cb10-17" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Discriminator(nn.Module):</span>
<span id="cb10-18"><a href="#cb10-18" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb10-19"><a href="#cb10-19" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>(Discriminator, <span class="va">self</span>).<span class="fu">__init__</span>()</span>
<span id="cb10-20"><a href="#cb10-20" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.model <span class="op">=</span> nn.Sequential(</span>
<span id="cb10-21"><a href="#cb10-21" aria-hidden="true" tabindex="-1"></a>            nn.Linear(<span class="dv">784</span>, <span class="dv">128</span>),</span>
<span id="cb10-22"><a href="#cb10-22" aria-hidden="true" tabindex="-1"></a>            nn.ReLU(),</span>
<span id="cb10-23"><a href="#cb10-23" aria-hidden="true" tabindex="-1"></a>            nn.Linear(<span class="dv">128</span>, <span class="dv">1</span>),</span>
<span id="cb10-24"><a href="#cb10-24" aria-hidden="true" tabindex="-1"></a>            nn.Sigmoid()</span>
<span id="cb10-25"><a href="#cb10-25" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb10-26"><a href="#cb10-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-27"><a href="#cb10-27" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, img):</span>
<span id="cb10-28"><a href="#cb10-28" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.model(img)</span></code></pre></div></li>
</ul>
<h3 id="chainer">Chainer</h3>
<ul>
<li><p><strong>Features</strong>:</p>
<ul>
<li>Define-by-run way for flexible network design</li>
<li>Good for research and fast prototyping</li>
</ul></li>
<li><p><strong>Installation</strong>:</p>
<div class="sourceCode" id="cb11"><pre
class="sourceCode bash"><code class="sourceCode bash"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="ex">pip</span> install chainer</span></code></pre></div></li>
<li><p><strong>Example Code</strong>:</p>
<div class="sourceCode" id="cb12"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> chainer</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> chainer.functions <span class="im">as</span> F</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> chainer.links <span class="im">as</span> L</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Generator(chainer.Chain):</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>(Generator, <span class="va">self</span>).<span class="fu">__init__</span>()</span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>        <span class="cf">with</span> <span class="va">self</span>.init_scope():</span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.fc1 <span class="op">=</span> L.Linear(<span class="dv">100</span>, <span class="dv">128</span>)</span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.fc2 <span class="op">=</span> L.Linear(<span class="dv">128</span>, <span class="dv">784</span>)</span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__call__</span>(<span class="va">self</span>, z):</span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a>        h <span class="op">=</span> F.relu(<span class="va">self</span>.fc1(z))</span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> F.tanh(<span class="va">self</span>.fc2(h))</span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-16"><a href="#cb12-16" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Discriminator(chainer.Chain):</span>
<span id="cb12-17"><a href="#cb12-17" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb12-18"><a href="#cb12-18" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>(Discriminator, <span class="va">self</span>).<span class="fu">__init__</span>()</span>
<span id="cb12-19"><a href="#cb12-19" aria-hidden="true" tabindex="-1"></a>        <span class="cf">with</span> <span class="va">self</span>.init_scope():</span>
<span id="cb12-20"><a href="#cb12-20" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.fc1 <span class="op">=</span> L.Linear(<span class="dv">784</span>, <span class="dv">128</span>)</span>
<span id="cb12-21"><a href="#cb12-21" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.fc2 <span class="op">=</span> L.Linear(<span class="dv">128</span>, <span class="dv">1</span>)</span>
<span id="cb12-22"><a href="#cb12-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-23"><a href="#cb12-23" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__call__</span>(<span class="va">self</span>, img):</span>
<span id="cb12-24"><a href="#cb12-24" aria-hidden="true" tabindex="-1"></a>        h <span class="op">=</span> F.relu(<span class="va">self</span>.fc1(img))</span>
<span id="cb12-25"><a href="#cb12-25" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> F.sigmoid(<span class="va">self</span>.fc2(h))</span></code></pre></div></li>
</ul>
<h3 id="summary-of-framework-selection">Summary of Framework
Selection</h3>
<p>When we choose a framework for GAN training, we should think about
these things: - <strong>Ease of Use</strong>: Find easy APIs and
community help - <strong>Flexibility</strong>: Pick between static or
dynamic computation graphs based on what we need -
<strong>Performance</strong>: Check GPU support and how well it
optimizes</p>
<p>For more information on how to start with generative AI and
frameworks, see this <a
href="https://bestonlinetutorial.com/generative_ai/what-are-the-steps-to-get-started-with-generative-ai-a-beginners-guide.html">beginner’s
guide</a>.</p>
<h2 id="preparing-your-dataset-for-gan-training">Preparing Your Dataset
for GAN Training</h2>
<p>Preparing our dataset is very important for good GAN training. Let’s
look at the steps we can follow:</p>
<ol type="1">
<li><p><strong>Data Collection</strong>: We need to gather images or
data points that relate to what our GAN does. It is key to have a big
enough dataset to cover the main patterns.</p></li>
<li><p><strong>Data Preprocessing</strong>:</p>
<ul>
<li><strong>Normalization</strong>: We should scale pixel values to a
range of [-1, 1] or [0, 1], based on the activation functions we
use.</li>
<li><strong>Resizing</strong>: It is good to resize all images to the
same size, like 64x64 pixels.</li>
<li><strong>Augmentation</strong>: We can use techniques like rotation,
flipping, or cropping to make our dataset more varied.</li>
</ul>
<p>Here is an example in Python using Pillow for resizing:</p>
<div class="sourceCode" id="cb13"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> PIL <span class="im">import</span> Image</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> resize_images(input_folder, output_folder, size<span class="op">=</span>(<span class="dv">64</span>, <span class="dv">64</span>)):</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> os.path.exists(output_folder):</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>        os.makedirs(output_folder)</span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> filename <span class="kw">in</span> os.listdir(input_folder):</span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> filename.endswith(<span class="st">&quot;.jpg&quot;</span>) <span class="kw">or</span> filename.endswith(<span class="st">&quot;.png&quot;</span>):</span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a>            img <span class="op">=</span> Image.<span class="bu">open</span>(os.path.join(input_folder, filename))</span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a>            img <span class="op">=</span> img.resize(size)</span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a>            img.save(os.path.join(output_folder, filename))</span></code></pre></div></li>
<li><p><strong>Dataset Format</strong>: We need to change the dataset
into a format that is good for our training framework, like TFRecords
for TensorFlow or custom datasets for PyTorch.</p></li>
<li><p><strong>Data Splitting</strong>: We should split our dataset into
training, validation, and test sets if needed. A common way to split is
70% for training, 15% for validation, and 15% for testing.</p></li>
<li><p><strong>Loading the Dataset</strong>: We will use data loaders
from our chosen framework to load batches of images when we train.</p>
<p>Here is an example in PyTorch:</p>
<div class="sourceCode" id="cb14"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchvision <span class="im">import</span> datasets, transforms</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>transform <span class="op">=</span> transforms.Compose([</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>    transforms.Resize((<span class="dv">64</span>, <span class="dv">64</span>)),</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>    transforms.ToTensor(),</span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>    transforms.Normalize((<span class="fl">0.5</span>,), (<span class="fl">0.5</span>,))</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a>dataset <span class="op">=</span> datasets.ImageFolder(root<span class="op">=</span><span class="st">&#39;path_to_your_dataset&#39;</span>, transform<span class="op">=</span>transform)</span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a>dataloader <span class="op">=</span> torch.utils.data.DataLoader(dataset, batch_size<span class="op">=</span><span class="dv">64</span>, shuffle<span class="op">=</span><span class="va">True</span>)</span></code></pre></div></li>
<li><p><strong>Data Quality Check</strong>: We need to check that our
dataset does not have any broken images or extra data that does not
belong. We can look at the images ourselves or use some automated
checks.</p></li>
</ol>
<p>By following these steps, we can prepare our dataset well. This way,
we can have better training results for our GAN. For more about starting
with generative AI, check out this <a
href="https://bestonlinetutorial.com/generative_ai/what-are-the-steps-to-get-started-with-generative-ai-a-beginners-guide.html">beginner’s
guide</a>.</p>
<h2
id="designing-the-generator-and-discriminator-models-for-gan-training">Designing
the Generator and Discriminator Models for GAN Training</h2>
<p>When we design the generator and discriminator models for GAN
training, we need to know their roles and how they are built. The
generator makes fake data. The discriminator checks if the data is real
or fake. Let’s look at how to design these models step by step.</p>
<h3 id="generator-model">Generator Model</h3>
<p>The generator uses transposed convolution layers. Some people call
them deconvolution layers. Here is a simple example using
TensorFlow/Keras:</p>
<div class="sourceCode" id="cb15"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow.keras.models <span class="im">import</span> Sequential</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow.keras.layers <span class="im">import</span> Dense, Reshape, LeakyReLU, Conv2DTranspose, BatchNormalization</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> build_generator(latent_dim):</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> Sequential()</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>    model.add(Dense(<span class="dv">128</span> <span class="op">*</span> <span class="dv">8</span> <span class="op">*</span> <span class="dv">8</span>, input_dim<span class="op">=</span>latent_dim))</span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a>    model.add(LeakyReLU(alpha<span class="op">=</span><span class="fl">0.2</span>))</span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a>    model.add(BatchNormalization(momentum<span class="op">=</span><span class="fl">0.8</span>))</span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a>    model.add(Reshape((<span class="dv">8</span>, <span class="dv">8</span>, <span class="dv">128</span>)))</span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a>    model.add(Conv2DTranspose(<span class="dv">128</span>, kernel_size<span class="op">=</span><span class="dv">4</span>, strides<span class="op">=</span><span class="dv">2</span>, padding<span class="op">=</span><span class="st">&#39;same&#39;</span>))</span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a>    model.add(LeakyReLU(alpha<span class="op">=</span><span class="fl">0.2</span>))</span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a>    model.add(BatchNormalization(momentum<span class="op">=</span><span class="fl">0.8</span>))</span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-15"><a href="#cb15-15" aria-hidden="true" tabindex="-1"></a>    model.add(Conv2DTranspose(<span class="dv">64</span>, kernel_size<span class="op">=</span><span class="dv">4</span>, strides<span class="op">=</span><span class="dv">2</span>, padding<span class="op">=</span><span class="st">&#39;same&#39;</span>))</span>
<span id="cb15-16"><a href="#cb15-16" aria-hidden="true" tabindex="-1"></a>    model.add(LeakyReLU(alpha<span class="op">=</span><span class="fl">0.2</span>))</span>
<span id="cb15-17"><a href="#cb15-17" aria-hidden="true" tabindex="-1"></a>    model.add(BatchNormalization(momentum<span class="op">=</span><span class="fl">0.8</span>))</span>
<span id="cb15-18"><a href="#cb15-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-19"><a href="#cb15-19" aria-hidden="true" tabindex="-1"></a>    model.add(Conv2DTranspose(<span class="dv">1</span>, kernel_size<span class="op">=</span><span class="dv">7</span>, activation<span class="op">=</span><span class="st">&#39;tanh&#39;</span>, padding<span class="op">=</span><span class="st">&#39;same&#39;</span>))</span>
<span id="cb15-20"><a href="#cb15-20" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb15-21"><a href="#cb15-21" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> model</span>
<span id="cb15-22"><a href="#cb15-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-23"><a href="#cb15-23" aria-hidden="true" tabindex="-1"></a>latent_dim <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb15-24"><a href="#cb15-24" aria-hidden="true" tabindex="-1"></a>generator <span class="op">=</span> build_generator(latent_dim)</span>
<span id="cb15-25"><a href="#cb15-25" aria-hidden="true" tabindex="-1"></a>generator.summary()</span></code></pre></div>
<h3 id="discriminator-model">Discriminator Model</h3>
<p>The discriminator uses convolutional layers. It classifies images as
real or fake. Here is an example:</p>
<div class="sourceCode" id="cb16"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow.keras.layers <span class="im">import</span> Conv2D, Flatten, Dropout</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> build_discriminator(img_shape):</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> Sequential()</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>    model.add(Conv2D(<span class="dv">64</span>, kernel_size<span class="op">=</span><span class="dv">3</span>, strides<span class="op">=</span><span class="dv">2</span>, padding<span class="op">=</span><span class="st">&#39;same&#39;</span>, input_shape<span class="op">=</span>img_shape))</span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>    model.add(LeakyReLU(alpha<span class="op">=</span><span class="fl">0.2</span>))</span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a>    model.add(Dropout(<span class="fl">0.25</span>))</span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a>    model.add(Conv2D(<span class="dv">128</span>, kernel_size<span class="op">=</span><span class="dv">3</span>, strides<span class="op">=</span><span class="dv">2</span>, padding<span class="op">=</span><span class="st">&#39;same&#39;</span>))</span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a>    model.add(LeakyReLU(alpha<span class="op">=</span><span class="fl">0.2</span>))</span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a>    model.add(Dropout(<span class="fl">0.25</span>))</span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a>    model.add(Flatten())</span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a>    model.add(Dense(<span class="dv">1</span>, activation<span class="op">=</span><span class="st">&#39;sigmoid&#39;</span>))</span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> model</span>
<span id="cb16-17"><a href="#cb16-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-18"><a href="#cb16-18" aria-hidden="true" tabindex="-1"></a>img_shape <span class="op">=</span> (<span class="dv">28</span>, <span class="dv">28</span>, <span class="dv">1</span>)  <span class="co"># Example for MNIST dataset</span></span>
<span id="cb16-19"><a href="#cb16-19" aria-hidden="true" tabindex="-1"></a>discriminator <span class="op">=</span> build_discriminator(img_shape)</span>
<span id="cb16-20"><a href="#cb16-20" aria-hidden="true" tabindex="-1"></a>discriminator.summary()</span></code></pre></div>
<h3 id="summary-of-model-properties">Summary of Model Properties</h3>
<ul>
<li><strong>Generator</strong>:
<ul>
<li>Input: Random noise (latent vector)</li>
<li>Output: Generated image</li>
<li>Layers: Dense, Reshape, Conv2DTranspose, BatchNormalization,
LeakyReLU</li>
</ul></li>
<li><strong>Discriminator</strong>:
<ul>
<li>Input: Image (real or generated)</li>
<li>Output: Probability (real or fake)</li>
<li>Layers: Conv2D, Flatten, Dense, Dropout, LeakyReLU</li>
</ul></li>
</ul>
<h3 id="training-configuration">Training Configuration</h3>
<p>We need to compile the models before we start training:</p>
<div class="sourceCode" id="cb17"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow.keras.optimizers <span class="im">import</span> Adam</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>discriminator.<span class="bu">compile</span>(loss<span class="op">=</span><span class="st">&#39;binary_crossentropy&#39;</span>, optimizer<span class="op">=</span>Adam(<span class="fl">0.0002</span>, <span class="fl">0.5</span>), metrics<span class="op">=</span>[<span class="st">&#39;accuracy&#39;</span>])</span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Combine models for training</span></span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>discriminator.trainable <span class="op">=</span> <span class="va">False</span></span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a>gan_input <span class="op">=</span> Input(shape<span class="op">=</span>(latent_dim,))</span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a>generated_image <span class="op">=</span> generator(gan_input)</span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a>gan_output <span class="op">=</span> discriminator(generated_image)</span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a>gan <span class="op">=</span> Model(gan_input, gan_output)</span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a>gan.<span class="bu">compile</span>(loss<span class="op">=</span><span class="st">&#39;binary_crossentropy&#39;</span>, optimizer<span class="op">=</span>Adam(<span class="fl">0.0002</span>, <span class="fl">0.5</span>))</span></code></pre></div>
<p>We should understand how to design the generator and discriminator
models well. This is very important for GAN training. For more info on
generative models, check this <a
href="https://bestonlinetutorial.com/generative_ai/what-is-generative-ai-and-how-does-it-work-a-comprehensive-guide.html">guide
on generative AI</a>.</p>
<h2
id="training-the-gan-how-to-monitor-progress-and-tune-hyperparameters">Training
the GAN How to Monitor Progress and Tune Hyperparameters</h2>
<p>We need to keep an eye on how a Generative Adversarial Network (GAN)
is training. Also, we have to tune its hyperparameters to get the best
performance. Here’s a simple way to monitor GAN training and adjust
hyperparameters step by step.</p>
<h3 id="monitoring-training-progress">Monitoring Training Progress</h3>
<ol type="1">
<li><p><strong>Loss Curves</strong>: We should track the loss for both
the generator and discriminator. This helps us see if they are learning
well. Ideally, both losses go down over time. But they should not get
too far apart.</p>
<div class="sourceCode" id="cb18"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_losses(generator_losses, discriminator_losses):</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>    plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">5</span>))</span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>    plt.plot(generator_losses, label<span class="op">=</span><span class="st">&#39;Generator Loss&#39;</span>)</span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>    plt.plot(discriminator_losses, label<span class="op">=</span><span class="st">&#39;Discriminator Loss&#39;</span>)</span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a>    plt.xlabel(<span class="st">&#39;Epochs&#39;</span>)</span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a>    plt.ylabel(<span class="st">&#39;Loss&#39;</span>)</span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="st">&#39;GAN Training Losses&#39;</span>)</span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a>    plt.legend()</span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a>    plt.show()</span></code></pre></div></li>
<li><p><strong>Generated Samples</strong>: We need to generate samples
from the generator often. This helps us check the quality of outputs at
different training stages.</p>
<div class="sourceCode" id="cb19"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> generate_images(generator, epoch, examples<span class="op">=</span><span class="dv">10</span>):</span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>    noise <span class="op">=</span> np.random.normal(<span class="dv">0</span>, <span class="dv">1</span>, (examples, <span class="dv">100</span>))  <span class="co"># Change dimensions if needed</span></span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>    generated_images <span class="op">=</span> generator.predict(noise)</span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Code to plot generated images</span></span></code></pre></div></li>
<li><p><strong>Inception Score (IS) or Fréchet Inception Distance
(FID)</strong>: We can use these measurements to check the quality of
generated samples in a numerical way.</p>
<div class="sourceCode" id="cb20"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> keras.applications.inception_v3 <span class="im">import</span> InceptionV3</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> keras.preprocessing.image <span class="im">import</span> ImageDataGenerator</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> calculate_fid(model, images1, images2):</span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Add FID calculation logic here</span></span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">pass</span></span></code></pre></div></li>
</ol>
<h3 id="tuning-hyperparameters">Tuning Hyperparameters</h3>
<ol type="1">
<li><p><strong>Learning Rates</strong>: We should try different learning
rates for the generator and discriminator. A good starting point is
0.0002 for both.</p>
<div class="sourceCode" id="cb21"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> keras.optimizers <span class="im">import</span> Adam</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>generator_optimizer <span class="op">=</span> Adam(learning_rate<span class="op">=</span><span class="fl">0.0002</span>, beta_1<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a>discriminator_optimizer <span class="op">=</span> Adam(learning_rate<span class="op">=</span><span class="fl">0.0002</span>, beta_1<span class="op">=</span><span class="fl">0.5</span>)</span></code></pre></div></li>
<li><p><strong>Batch Size</strong>: We can test different batch sizes to
see how it affects training. Common sizes are from 32 to 128.</p></li>
<li><p><strong>Number of Epochs</strong>: We should watch the training
for enough epochs. But be careful about overfitting. Use early stopping
based on how validation performs.</p></li>
<li><p><strong>Noise Dimension</strong>: We might experiment with the
size of the input noise vector. Common sizes are 100 or 128 for image
tasks.</p></li>
<li><p><strong>Model Architecture</strong>: We can change the number of
layers and units in the generator and discriminator. A deeper model can
learn more complex patterns but might cause training issues.</p></li>
<li><p><strong>Regularization Techniques</strong>: We should use
techniques like dropout or batch normalization to help with GAN training
stability.</p></li>
</ol>
<h3 id="example-of-tuning-in-code">Example of Tuning in Code</h3>
<div class="sourceCode" id="cb22"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> keras.layers <span class="im">import</span> Dense, Reshape, Flatten</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> keras.models <span class="im">import</span> Sequential</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> build_generator():</span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> Sequential()</span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a>    model.add(Dense(<span class="dv">256</span>, input_dim<span class="op">=</span><span class="dv">100</span>, activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>))</span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a>    model.add(Dense(<span class="dv">512</span>, activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>))</span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a>    model.add(Dense(<span class="dv">1024</span>, activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>))</span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a>    model.add(Dense(<span class="dv">28</span> <span class="op">*</span> <span class="dv">28</span> <span class="op">*</span> <span class="dv">1</span>, activation<span class="op">=</span><span class="st">&#39;tanh&#39;</span>))</span>
<span id="cb22-10"><a href="#cb22-10" aria-hidden="true" tabindex="-1"></a>    model.add(Reshape((<span class="dv">28</span>, <span class="dv">28</span>, <span class="dv">1</span>)))</span>
<span id="cb22-11"><a href="#cb22-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> model</span>
<span id="cb22-12"><a href="#cb22-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-13"><a href="#cb22-13" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> build_discriminator():</span>
<span id="cb22-14"><a href="#cb22-14" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> Sequential()</span>
<span id="cb22-15"><a href="#cb22-15" aria-hidden="true" tabindex="-1"></a>    model.add(Flatten(input_shape<span class="op">=</span>(<span class="dv">28</span>, <span class="dv">28</span>, <span class="dv">1</span>)))</span>
<span id="cb22-16"><a href="#cb22-16" aria-hidden="true" tabindex="-1"></a>    model.add(Dense(<span class="dv">512</span>, activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>))</span>
<span id="cb22-17"><a href="#cb22-17" aria-hidden="true" tabindex="-1"></a>    model.add(Dense(<span class="dv">256</span>, activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>))</span>
<span id="cb22-18"><a href="#cb22-18" aria-hidden="true" tabindex="-1"></a>    model.add(Dense(<span class="dv">1</span>, activation<span class="op">=</span><span class="st">&#39;sigmoid&#39;</span>))</span>
<span id="cb22-19"><a href="#cb22-19" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> model</span></code></pre></div>
<p>By watching these parts closely and tuning the hyperparameters, we
can make our GAN much better. For more information about GANs, we can
check out <a
href="https://bestonlinetutorial.com/generative_ai/what-is-generative-ai-and-how-does-it-work-a-comprehensive-guide.html">this
guide on generative AI</a>.</p>
<h2 id="practical-examples-of-training-a-gan-with-code">Practical
Examples of Training a GAN with Code</h2>
<p>In this section, we show simple examples of training a Generative
Adversarial Network (GAN) using Python and TensorFlow/Keras. The code
snippets below demonstrate the main parts of building and training a
GAN.</p>
<h3 id="example-1-simple-gan-for-image-generation">Example 1: Simple GAN
for Image Generation</h3>
<p>This example shows a basic GAN that generates handwritten digits from
the MNIST dataset.</p>
<div class="sourceCode" id="cb23"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> keras.datasets <span class="im">import</span> mnist</span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> keras.models <span class="im">import</span> Sequential</span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> keras.layers <span class="im">import</span> Dense, Reshape, Flatten, Dropout</span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> keras.optimizers <span class="im">import</span> Adam</span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Load and preprocess the MNIST dataset</span></span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a>(X_train, _), (_, _) <span class="op">=</span> mnist.load_data()</span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a>X_train <span class="op">=</span> X_train <span class="op">/</span> <span class="fl">127.5</span> <span class="op">-</span> <span class="fl">1.</span>  <span class="co"># Normalize to [-1, 1]</span></span>
<span id="cb23-11"><a href="#cb23-11" aria-hidden="true" tabindex="-1"></a>X_train <span class="op">=</span> np.expand_dims(X_train, axis<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb23-12"><a href="#cb23-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-13"><a href="#cb23-13" aria-hidden="true" tabindex="-1"></a><span class="co"># GAN parameters</span></span>
<span id="cb23-14"><a href="#cb23-14" aria-hidden="true" tabindex="-1"></a>latent_dim <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb23-15"><a href="#cb23-15" aria-hidden="true" tabindex="-1"></a>adam <span class="op">=</span> Adam(<span class="fl">0.0002</span>, <span class="fl">0.5</span>)</span>
<span id="cb23-16"><a href="#cb23-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-17"><a href="#cb23-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Build Generator</span></span>
<span id="cb23-18"><a href="#cb23-18" aria-hidden="true" tabindex="-1"></a>generator <span class="op">=</span> Sequential([</span>
<span id="cb23-19"><a href="#cb23-19" aria-hidden="true" tabindex="-1"></a>    Dense(<span class="dv">256</span>, activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>, input_dim<span class="op">=</span>latent_dim),</span>
<span id="cb23-20"><a href="#cb23-20" aria-hidden="true" tabindex="-1"></a>    Dense(<span class="dv">512</span>, activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>),</span>
<span id="cb23-21"><a href="#cb23-21" aria-hidden="true" tabindex="-1"></a>    Dense(<span class="dv">1024</span>, activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>),</span>
<span id="cb23-22"><a href="#cb23-22" aria-hidden="true" tabindex="-1"></a>    Dense(<span class="dv">28</span> <span class="op">*</span> <span class="dv">28</span> <span class="op">*</span> <span class="dv">1</span>, activation<span class="op">=</span><span class="st">&#39;tanh&#39;</span>),</span>
<span id="cb23-23"><a href="#cb23-23" aria-hidden="true" tabindex="-1"></a>    Reshape((<span class="dv">28</span>, <span class="dv">28</span>, <span class="dv">1</span>))</span>
<span id="cb23-24"><a href="#cb23-24" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb23-25"><a href="#cb23-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-26"><a href="#cb23-26" aria-hidden="true" tabindex="-1"></a><span class="co"># Build Discriminator</span></span>
<span id="cb23-27"><a href="#cb23-27" aria-hidden="true" tabindex="-1"></a>discriminator <span class="op">=</span> Sequential([</span>
<span id="cb23-28"><a href="#cb23-28" aria-hidden="true" tabindex="-1"></a>    Flatten(input_shape<span class="op">=</span>(<span class="dv">28</span>, <span class="dv">28</span>, <span class="dv">1</span>)),</span>
<span id="cb23-29"><a href="#cb23-29" aria-hidden="true" tabindex="-1"></a>    Dense(<span class="dv">512</span>, activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>),</span>
<span id="cb23-30"><a href="#cb23-30" aria-hidden="true" tabindex="-1"></a>    Dropout(<span class="fl">0.3</span>),</span>
<span id="cb23-31"><a href="#cb23-31" aria-hidden="true" tabindex="-1"></a>    Dense(<span class="dv">256</span>, activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>),</span>
<span id="cb23-32"><a href="#cb23-32" aria-hidden="true" tabindex="-1"></a>    Dense(<span class="dv">1</span>, activation<span class="op">=</span><span class="st">&#39;sigmoid&#39;</span>)</span>
<span id="cb23-33"><a href="#cb23-33" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb23-34"><a href="#cb23-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-35"><a href="#cb23-35" aria-hidden="true" tabindex="-1"></a><span class="co"># Compile Discriminator</span></span>
<span id="cb23-36"><a href="#cb23-36" aria-hidden="true" tabindex="-1"></a>discriminator.<span class="bu">compile</span>(loss<span class="op">=</span><span class="st">&#39;binary_crossentropy&#39;</span>, optimizer<span class="op">=</span>adam, metrics<span class="op">=</span>[<span class="st">&#39;accuracy&#39;</span>])</span>
<span id="cb23-37"><a href="#cb23-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-38"><a href="#cb23-38" aria-hidden="true" tabindex="-1"></a><span class="co"># Create GAN model</span></span>
<span id="cb23-39"><a href="#cb23-39" aria-hidden="true" tabindex="-1"></a>discriminator.trainable <span class="op">=</span> <span class="va">False</span></span>
<span id="cb23-40"><a href="#cb23-40" aria-hidden="true" tabindex="-1"></a>gan_input <span class="op">=</span> Sequential([generator])</span>
<span id="cb23-41"><a href="#cb23-41" aria-hidden="true" tabindex="-1"></a>gan_output <span class="op">=</span> discriminator(gan_input.output)</span>
<span id="cb23-42"><a href="#cb23-42" aria-hidden="true" tabindex="-1"></a>gan <span class="op">=</span> Sequential([gan_input, gan_output])</span>
<span id="cb23-43"><a href="#cb23-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-44"><a href="#cb23-44" aria-hidden="true" tabindex="-1"></a><span class="co"># Compile GAN</span></span>
<span id="cb23-45"><a href="#cb23-45" aria-hidden="true" tabindex="-1"></a>gan.<span class="bu">compile</span>(loss<span class="op">=</span><span class="st">&#39;binary_crossentropy&#39;</span>, optimizer<span class="op">=</span>adam)</span>
<span id="cb23-46"><a href="#cb23-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-47"><a href="#cb23-47" aria-hidden="true" tabindex="-1"></a><span class="co"># Training the GAN</span></span>
<span id="cb23-48"><a href="#cb23-48" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> train_gan(epochs, batch_size):</span>
<span id="cb23-49"><a href="#cb23-49" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(epochs):</span>
<span id="cb23-50"><a href="#cb23-50" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Train Discriminator</span></span>
<span id="cb23-51"><a href="#cb23-51" aria-hidden="true" tabindex="-1"></a>        idx <span class="op">=</span> np.random.randint(<span class="dv">0</span>, X_train.shape[<span class="dv">0</span>], batch_size)</span>
<span id="cb23-52"><a href="#cb23-52" aria-hidden="true" tabindex="-1"></a>        real_imgs <span class="op">=</span> X_train[idx]</span>
<span id="cb23-53"><a href="#cb23-53" aria-hidden="true" tabindex="-1"></a>        noise <span class="op">=</span> np.random.normal(<span class="dv">0</span>, <span class="dv">1</span>, (batch_size, latent_dim))</span>
<span id="cb23-54"><a href="#cb23-54" aria-hidden="true" tabindex="-1"></a>        fake_imgs <span class="op">=</span> generator.predict(noise)</span>
<span id="cb23-55"><a href="#cb23-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-56"><a href="#cb23-56" aria-hidden="true" tabindex="-1"></a>        d_loss_real <span class="op">=</span> discriminator.train_on_batch(real_imgs, np.ones((batch_size, <span class="dv">1</span>)))</span>
<span id="cb23-57"><a href="#cb23-57" aria-hidden="true" tabindex="-1"></a>        d_loss_fake <span class="op">=</span> discriminator.train_on_batch(fake_imgs, np.zeros((batch_size, <span class="dv">1</span>)))</span>
<span id="cb23-58"><a href="#cb23-58" aria-hidden="true" tabindex="-1"></a>        d_loss <span class="op">=</span> <span class="fl">0.5</span> <span class="op">*</span> np.add(d_loss_real, d_loss_fake)</span>
<span id="cb23-59"><a href="#cb23-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-60"><a href="#cb23-60" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Train Generator</span></span>
<span id="cb23-61"><a href="#cb23-61" aria-hidden="true" tabindex="-1"></a>        noise <span class="op">=</span> np.random.normal(<span class="dv">0</span>, <span class="dv">1</span>, (batch_size, latent_dim))</span>
<span id="cb23-62"><a href="#cb23-62" aria-hidden="true" tabindex="-1"></a>        g_loss <span class="op">=</span> gan.train_on_batch(noise, np.ones((batch_size, <span class="dv">1</span>)))</span>
<span id="cb23-63"><a href="#cb23-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-64"><a href="#cb23-64" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> epoch <span class="op">%</span> <span class="dv">1000</span> <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb23-65"><a href="#cb23-65" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f&quot;</span><span class="sc">{</span>epoch<span class="sc">}</span><span class="ss"> [D loss: </span><span class="sc">{</span>d_loss[<span class="dv">0</span>]<span class="sc">:.4f}</span><span class="ss">, acc.: </span><span class="sc">{</span><span class="dv">100</span><span class="op">*</span>d_loss[<span class="dv">1</span>]<span class="sc">:.2f}</span><span class="ss">%] [G loss: </span><span class="sc">{</span>g_loss<span class="sc">:.4f}</span><span class="ss">]&quot;</span>)</span>
<span id="cb23-66"><a href="#cb23-66" aria-hidden="true" tabindex="-1"></a>            save_generated_images(epoch)</span>
<span id="cb23-67"><a href="#cb23-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-68"><a href="#cb23-68" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> save_generated_images(epoch):</span>
<span id="cb23-69"><a href="#cb23-69" aria-hidden="true" tabindex="-1"></a>    noise <span class="op">=</span> np.random.normal(<span class="dv">0</span>, <span class="dv">1</span>, (<span class="dv">10</span>, latent_dim))</span>
<span id="cb23-70"><a href="#cb23-70" aria-hidden="true" tabindex="-1"></a>    generated_images <span class="op">=</span> generator.predict(noise)</span>
<span id="cb23-71"><a href="#cb23-71" aria-hidden="true" tabindex="-1"></a>    generated_images <span class="op">=</span> <span class="fl">0.5</span> <span class="op">*</span> generated_images <span class="op">+</span> <span class="fl">0.5</span>  <span class="co"># Rescale to [0, 1]</span></span>
<span id="cb23-72"><a href="#cb23-72" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-73"><a href="#cb23-73" aria-hidden="true" tabindex="-1"></a>    plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">10</span>))</span>
<span id="cb23-74"><a href="#cb23-74" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(generated_images.shape[<span class="dv">0</span>]):</span>
<span id="cb23-75"><a href="#cb23-75" aria-hidden="true" tabindex="-1"></a>        plt.subplot(<span class="dv">5</span>, <span class="dv">5</span>, i <span class="op">+</span> <span class="dv">1</span>)</span>
<span id="cb23-76"><a href="#cb23-76" aria-hidden="true" tabindex="-1"></a>        plt.imshow(generated_images[i, :, :, <span class="dv">0</span>], cmap<span class="op">=</span><span class="st">&#39;gray&#39;</span>)</span>
<span id="cb23-77"><a href="#cb23-77" aria-hidden="true" tabindex="-1"></a>        plt.axis(<span class="st">&#39;off&#39;</span>)</span>
<span id="cb23-78"><a href="#cb23-78" aria-hidden="true" tabindex="-1"></a>    plt.savefig(<span class="ss">f&quot;gan_generated_epoch_</span><span class="sc">{</span>epoch<span class="sc">}</span><span class="ss">.png&quot;</span>)</span>
<span id="cb23-79"><a href="#cb23-79" aria-hidden="true" tabindex="-1"></a>    plt.close()</span>
<span id="cb23-80"><a href="#cb23-80" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-81"><a href="#cb23-81" aria-hidden="true" tabindex="-1"></a>train_gan(epochs<span class="op">=</span><span class="dv">10000</span>, batch_size<span class="op">=</span><span class="dv">128</span>)</span></code></pre></div>
<h3 id="example-2-conditional-gan-cgan">Example 2: Conditional GAN
(cGAN)</h3>
<p>This example shows how to make a Conditional GAN that generates
images based on specific labels.</p>
<div class="sourceCode" id="cb24"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> keras.layers <span class="im">import</span> Embedding, Multiply</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Modify the Generator and Discriminator to include labels</span></span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> build_generator():</span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> Sequential()</span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a>    model.add(Dense(<span class="dv">256</span>, activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>, input_dim<span class="op">=</span>latent_dim <span class="op">+</span> <span class="dv">10</span>))</span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a>    model.add(Dense(<span class="dv">512</span>, activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>))</span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a>    model.add(Dense(<span class="dv">1024</span>, activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>))</span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a>    model.add(Dense(<span class="dv">28</span> <span class="op">*</span> <span class="dv">28</span> <span class="op">*</span> <span class="dv">1</span>, activation<span class="op">=</span><span class="st">&#39;tanh&#39;</span>))</span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a>    model.add(Reshape((<span class="dv">28</span>, <span class="dv">28</span>, <span class="dv">1</span>)))</span>
<span id="cb24-11"><a href="#cb24-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> model</span>
<span id="cb24-12"><a href="#cb24-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-13"><a href="#cb24-13" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> build_discriminator():</span>
<span id="cb24-14"><a href="#cb24-14" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> Sequential()</span>
<span id="cb24-15"><a href="#cb24-15" aria-hidden="true" tabindex="-1"></a>    model.add(Flatten(input_shape<span class="op">=</span>(<span class="dv">28</span>, <span class="dv">28</span>, <span class="dv">1</span>)))</span>
<span id="cb24-16"><a href="#cb24-16" aria-hidden="true" tabindex="-1"></a>    model.add(Dense(<span class="dv">512</span>, activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>))</span>
<span id="cb24-17"><a href="#cb24-17" aria-hidden="true" tabindex="-1"></a>    model.add(Dropout(<span class="fl">0.3</span>))</span>
<span id="cb24-18"><a href="#cb24-18" aria-hidden="true" tabindex="-1"></a>    model.add(Dense(<span class="dv">256</span>, activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>))</span>
<span id="cb24-19"><a href="#cb24-19" aria-hidden="true" tabindex="-1"></a>    model.add(Dense(<span class="dv">1</span>, activation<span class="op">=</span><span class="st">&#39;sigmoid&#39;</span>))</span>
<span id="cb24-20"><a href="#cb24-20" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> model</span>
<span id="cb24-21"><a href="#cb24-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-22"><a href="#cb24-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Training function now includes labels</span></span>
<span id="cb24-23"><a href="#cb24-23" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> train_cgan(epochs, batch_size):</span>
<span id="cb24-24"><a href="#cb24-24" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(epochs):</span>
<span id="cb24-25"><a href="#cb24-25" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Generate random labels</span></span>
<span id="cb24-26"><a href="#cb24-26" aria-hidden="true" tabindex="-1"></a>        labels <span class="op">=</span> np.random.randint(<span class="dv">0</span>, <span class="dv">10</span>, batch_size)</span>
<span id="cb24-27"><a href="#cb24-27" aria-hidden="true" tabindex="-1"></a>        label_embeddings <span class="op">=</span> np.asarray([[<span class="dv">1</span> <span class="cf">if</span> i <span class="op">==</span> label <span class="cf">else</span> <span class="dv">0</span> <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">10</span>)] <span class="cf">for</span> label <span class="kw">in</span> labels])</span>
<span id="cb24-28"><a href="#cb24-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-29"><a href="#cb24-29" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Train Discriminator with labels</span></span>
<span id="cb24-30"><a href="#cb24-30" aria-hidden="true" tabindex="-1"></a>        real_imgs <span class="op">=</span> X_train[np.random.randint(<span class="dv">0</span>, X_train.shape[<span class="dv">0</span>], batch_size)]</span>
<span id="cb24-31"><a href="#cb24-31" aria-hidden="true" tabindex="-1"></a>        noise <span class="op">=</span> np.random.normal(<span class="dv">0</span>, <span class="dv">1</span>, (batch_size, latent_dim))</span>
<span id="cb24-32"><a href="#cb24-32" aria-hidden="true" tabindex="-1"></a>        noise_with_labels <span class="op">=</span> np.concatenate([noise, label_embeddings], axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb24-33"><a href="#cb24-33" aria-hidden="true" tabindex="-1"></a>        fake_imgs <span class="op">=</span> generator.predict(noise_with_labels)</span>
<span id="cb24-34"><a href="#cb24-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-35"><a href="#cb24-35" aria-hidden="true" tabindex="-1"></a>        d_loss_real <span class="op">=</span> discriminator.train_on_batch(real_imgs, np.ones((batch_size, <span class="dv">1</span>)))</span>
<span id="cb24-36"><a href="#cb24-36" aria-hidden="true" tabindex="-1"></a>        d_loss_fake <span class="op">=</span> discriminator.train_on_batch(fake_imgs, np.zeros((batch_size, <span class="dv">1</span>)))</span>
<span id="cb24-37"><a href="#cb24-37" aria-hidden="true" tabindex="-1"></a>        d_loss <span class="op">=</span> <span class="fl">0.5</span> <span class="op">*</span> np.add(d_loss_real, d_loss_fake)</span>
<span id="cb24-38"><a href="#cb24-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-39"><a href="#cb24-39" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Train Generator with labels</span></span>
<span id="cb24-40"><a href="#cb24-40" aria-hidden="true" tabindex="-1"></a>        noise <span class="op">=</span> np.random.normal(<span class="dv">0</span>, <span class="dv">1</span>, (batch_size, latent_dim))</span>
<span id="cb24-41"><a href="#cb24-41" aria-hidden="true" tabindex="-1"></a>        noise_with_labels <span class="op">=</span> np.concatenate([noise, label_embeddings], axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb24-42"><a href="#cb24-42" aria-hidden="true" tabindex="-1"></a>        g_loss <span class="op">=</span> gan.train_on_batch(noise_with_labels, np.ones((batch_size, <span class="dv">1</span>)))</span>
<span id="cb24-43"><a href="#cb24-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-44"><a href="#cb24-44" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> epoch <span class="op">%</span> <span class="dv">1000</span> <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb24-45"><a href="#cb24-45" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f&quot;</span><span class="sc">{</span>epoch<span class="sc">}</span><span class="ss"> [D loss: </span><span class="sc">{</span>d_loss[<span class="dv">0</span>]<span class="sc">:.4f}</span><span class="ss">, acc.: </span><span class="sc">{</span><span class="dv">100</span><span class="op">*</span>d_loss[<span class="dv">1</span>]<span class="sc">:.2f}</span><span class="ss">%] [G loss: </span><span class="sc">{</span>g_loss<span class="sc">:.4f}</span><span class="ss">]&quot;</span>)</span>
<span id="cb24-46"><a href="#cb24-46" aria-hidden="true" tabindex="-1"></a>            save_generated_images(epoch)</span>
<span id="cb24-47"><a href="#cb24-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-48"><a href="#cb24-48" aria-hidden="true" tabindex="-1"></a>train_cgan(epochs<span class="op">=</span><span class="dv">10000</span>, batch_size<span class="op">=</span><span class="dv">128</span>)</span></code></pre></div>
<p>These examples show how to make a basic GAN and a conditional GAN in
Python. For more insights on the key ideas of GANs, check <a
href="https://bestonlinetutorial.com/generative_ai/what-are-the-key-differences-between-generative-and-discriminative-models-understanding-their-unique-features-and-applications.html">What
Are the Key Differences Between Generative and Discriminative
Models</a>.</p>
<h2
id="common-challenges-when-training-a-gan-and-how-to-overcome-them">Common
Challenges When Training a GAN and How to Overcome Them</h2>
<p>Training Generative Adversarial Networks (GANs) can be hard. There
are many issues that can come up during this process. We will look at
some common problems and how to fix them.</p>
<ol type="1">
<li><strong>Mode Collapse</strong>: This happens when the generator only
makes a few types of outputs. To fix mode collapse, we can:
<ul>
<li>Use mini-batch discrimination.</li>
<li>Try using more than one generator to create different outputs.</li>
<li>Use unrolled GANs to make training more stable.</li>
</ul></li>
<li><strong>Vanishing Gradients</strong>: If the discriminator gets too
strong, the generator does not get enough feedback. We can solve this
by:
<ul>
<li>Balancing the training of the generator and discriminator. For
example, we can train the generator less often.</li>
<li>Using other loss functions like Wasserstein loss.</li>
</ul></li>
<li><strong>Divergence</strong>: Sometimes training can get unstable and
diverge. To help with this, we can:
<ul>
<li>Use a learning rate scheduler that changes the learning rate as
needed.</li>
<li>Apply gradient clipping to stop gradients from getting too big.</li>
</ul></li>
<li><strong>Overfitting</strong>: The discriminator might fit too
closely to the training data. This makes it hard for the generator to
learn. We can prevent this by:
<ul>
<li>Adding noise to the input data.</li>
<li>Using dropout layers in the discriminator.</li>
</ul></li>
<li><strong>Insufficient Training Data</strong>: If we have a small
dataset, it can limit what the GAN can learn. We can fix this by:
<ul>
<li>Using data augmentation to make the dataset bigger.</li>
<li>Doing transfer learning from models that are already trained.</li>
</ul></li>
<li><strong>Training Time</strong>: Training GANs can take a lot of
resources and time. To make it better, we can:
<ul>
<li>Use GPU acceleration.</li>
<li>Try smaller model designs when possible.</li>
</ul></li>
</ol>
<p>Here is an example of how to fix mode collapse in code:</p>
<div class="sourceCode" id="cb25"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Example of implementing mini-batch discrimination in TensorFlow</span></span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow.keras.layers <span class="im">import</span> Layer, Conv2D</span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> MiniBatchDiscrimination(Layer):</span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, num_kernels<span class="op">=</span><span class="dv">100</span>, kernel_dim<span class="op">=</span><span class="dv">5</span>):</span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>(MiniBatchDiscrimination, <span class="va">self</span>).<span class="fu">__init__</span>()</span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.num_kernels <span class="op">=</span> num_kernels</span>
<span id="cb25-9"><a href="#cb25-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.kernel_dim <span class="op">=</span> kernel_dim</span>
<span id="cb25-10"><a href="#cb25-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-11"><a href="#cb25-11" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> call(<span class="va">self</span>, inputs):</span>
<span id="cb25-12"><a href="#cb25-12" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Implement mini-batch discrimination logic here</span></span>
<span id="cb25-13"><a href="#cb25-13" aria-hidden="true" tabindex="-1"></a>        <span class="co"># This is a placeholder for the actual logic</span></span>
<span id="cb25-14"><a href="#cb25-14" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> inputs</span>
<span id="cb25-15"><a href="#cb25-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-16"><a href="#cb25-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Add to your discriminator model</span></span>
<span id="cb25-17"><a href="#cb25-17" aria-hidden="true" tabindex="-1"></a>discriminator <span class="op">=</span> Sequential([</span>
<span id="cb25-18"><a href="#cb25-18" aria-hidden="true" tabindex="-1"></a>    Conv2D(<span class="dv">64</span>, kernel_size<span class="op">=</span><span class="dv">5</span>, strides<span class="op">=</span><span class="dv">2</span>, padding<span class="op">=</span><span class="st">&#39;same&#39;</span>, activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>),</span>
<span id="cb25-19"><a href="#cb25-19" aria-hidden="true" tabindex="-1"></a>    MiniBatchDiscrimination()</span>
<span id="cb25-20"><a href="#cb25-20" aria-hidden="true" tabindex="-1"></a>])</span></code></pre></div>
<p>By knowing these problems and how to fix them, we can make our GAN
training better. If you want to learn more about generative models, you
can check the article on <a
href="https://bestonlinetutorial.com/generative_ai/what-are-the-real-life-applications-of-generative-ai.html">real-life
applications of generative AI</a>.</p>
<h2 id="frequently-asked-questions">Frequently Asked Questions</h2>
<h3 id="what-is-a-gan-and-how-does-it-work">1. What is a GAN and how
does it work?</h3>
<p>A Generative Adversarial Network (GAN) has two parts. We have the
generator and the discriminator. The generator makes fake data. The
discriminator checks if the data is real or fake. This back-and-forth
helps the generator get better at making realistic data over time. If
you want to learn more about GANs, you can read our article on the <a
href="https://bestonlinetutorial.com/generative_ai/what-are-the-key-differences-between-generative-and-discriminative-models-understanding-their-unique-features-and-applications.html">key
differences between generative and discriminative models</a>.</p>
<h3 id="how-do-i-prepare-my-dataset-for-gan-training">2. How do I
prepare my dataset for GAN training?</h3>
<p>To prepare your dataset for GAN training, we need to follow some
steps. First, we clean the data to remove noise. Next, we make sure to
have diverse samples. After that, we normalize the data. Finally, we
split it into training and validation sets. Good preparation is very
important for GAN training. It affects the quality of the data we
generate. You can learn more about starting with generative AI in our <a
href="https://bestonlinetutorial.com/generative_ai/what-are-the-steps-to-get-started-with-generative-ai-a-beginners-guide.html">beginner’s
guide</a>.</p>
<h3 id="what-frameworks-are-best-for-training-gans">3. What frameworks
are best for training GANs?</h3>
<p>We can use popular frameworks like TensorFlow and PyTorch for
training GANs. These frameworks give us many tools that help us develop
and train GANs easily. TensorFlow is good for scaling and deploying.
PyTorch is nice because it is easy to use and has a flexible computation
graph. Choosing the right framework can really change our GAN training
experience.</p>
<h3 id="what-are-common-challenges-faced-when-training-gans">4. What are
common challenges faced when training GANs?</h3>
<p>When we train GANs, we may face some common problems. These include
mode collapse, instability, and hard convergence. These problems can
come from not enough training data, bad model design, or wrong
hyperparameters. We can use some techniques to fix these issues. For
example, we can use mini-batch discrimination, feature matching, and
different architectures. This can make our GAN training stronger.</p>
<h3 id="how-can-i-monitor-the-progress-of-my-gan-training">5. How can I
monitor the progress of my GAN training?</h3>
<p>We can monitor GAN training progress using different metrics. One way
is to look at the loss values for both the generator and discriminator.
We can also see generated samples regularly to check the quality. Using
tools like TensorBoard can help us visualize the training in real time.
This makes it easier to adjust hyperparameters for better GAN
performance. For more on how neural networks improve generative AI,
check our article on <a
href="https://bestonlinetutorial.com/generative_ai/how-do-neural-networks-fuel-the-capabilities-of-generative-ai.html">how
neural networks fuel the capabilities of generative AI</a>.</p>

                        </div>

                    </div>
                    <!--//container-->
                </article>

            </div>
            <!--//main-wrapper-->

            <div id="footer-placeholder"></div>

            <!-- Javascript -->
            <script src="/assets/plugins/popper.min.js" defer></script>
            <script src="/assets/plugins/bootstrap/js/bootstrap.min.js" defer></script>
            <script src="/assets/fontawesome/js/all.min.js" defer></script>
        </body>

        </html>
            
            