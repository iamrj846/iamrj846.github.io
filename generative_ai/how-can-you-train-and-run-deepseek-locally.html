
    
            <!DOCTYPE html>
        <html lang="en">

        <head>
            <!-- Google tag (gtag.js) -->
            <script async src="https://www.googletagmanager.com/gtag/js?id=G-TFCQEJR7TD"></script>
            <script>
            window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
            gtag('config', 'G-TFCQEJR7TD');
            </script>
            <meta charset="utf-8">
            <meta http-equiv="X-UA-Compatible" content="IE=edge">
            <meta name="viewport" content="width=device-width, initial-scale=1.0">
            <!-- Common CSS & Icons -->
            <link rel="icon" href="/favicon.ico" type="image/x-icon">
            <link rel="stylesheet" href="/assets/plugins/highlight/styles/monokai-sublime.css">
            <link id="theme-style" rel="stylesheet" href="/assets/css/theme-8.css">
            <link rel="stylesheet" href="/assets/css/post.css">
            <title>How Can You Train and Run DeepSeek Locally?</title>
            <meta name="description" content="Learn how to train and run DeepSeek locally with our step-by-step guide. Maximize your AI capabilities today!">
            <script src="https://code.jquery.com/jquery-3.6.0.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>
	        <script src="/assets/js/blog.js"></script>
        </head>

        <body>

            <div id="header-placeholder"></div>

            <div class="main-wrapper">

                <article class="blog-post px-3 py-5 p-md-5">
                    <div class="container single-col-max-width">
                        <header class="blog-post-header">
                            <h1 class="title mb-2">How Can You Train and Run DeepSeek Locally?</h1>
                        </header>

                        <div class="blog-post-body">
                            <p>Training and running DeepSeek on our own computer needs some setup.
We must prepare our computing environment to use this deep learning
model properly. DeepSeek helps us analyze data better. It uses deep
learning to help us find important information from big datasets. When
we run DeepSeek locally, we can use its features without needing cloud
services. This gives us faster results and more control over how we
train the model.</p>
<p>In this article, we will look at different parts of training and
running DeepSeek locally for the best performance. We will talk about
how to set up our environment, install the needed programs, configure
DeepSeek, get our dataset ready, and run the training step by step. We
will also discuss how to check our model, run DeepSeek for inference,
and give some easy examples of using it locally. The next sections will
help us with our discussion:</p>
<ul>
<li>How to Train and Run DeepSeek Locally for Optimal Performance</li>
<li>Setting Up Your Environment to Train DeepSeek Locally</li>
<li>Installing Required Dependencies for DeepSeek Local Training</li>
<li>Configuring DeepSeek for Local Training</li>
<li>Preparing Your Dataset for DeepSeek Local Training</li>
<li>Training DeepSeek Locally Step by Step</li>
<li>Validating Your DeepSeek Model After Local Training</li>
<li>Running DeepSeek Locally for Inference</li>
<li>Practical Examples of Using DeepSeek Locally</li>
<li>Frequently Asked Questions</li>
</ul>
<p>If we want to learn more about generative AI and similar topics, we
can find useful info in articles like <a
href="https://bestonlinetutorial.com/generative_ai/what-is-generative-ai-and-how-does-it-work-a-comprehensive-guide.html">What
is Generative AI and How Does it Work?</a> and <a
href="https://bestonlinetutorial.com/generative_ai/how-can-you-train-a-gan-a-step-by-step-tutorial-guide.html">How
Can You Train a GAN?</a>. These articles give us more details about deep
learning methods.</p>
<h2 id="setting-up-your-environment-to-train-deepseek-locally">Setting
Up Your Environment to Train DeepSeek Locally</h2>
<p>To train DeepSeek on your computer, we need to set up the environment
in a good way. Let’s follow these steps to make sure everything works
well.</p>
<ol type="1">
<li><strong>System Requirements</strong>:
<ul>
<li>Operating System: Use Linux (Ubuntu is good) or Windows with
WSL.<br />
</li>
<li>Python: We need version 3.7 or higher.<br />
</li>
<li>GPU: An NVIDIA GPU with CUDA support is best for faster
training.</li>
</ul></li>
<li><strong>Install Anaconda</strong>:
<ul>
<li><p>First, we download and install Anaconda from <a
href="https://www.anaconda.com/products/distribution">Anaconda’s
website</a>.<br />
</p></li>
<li><p>Then, we create a new environment:</p>
<div class="sourceCode" id="cb1"><pre
class="sourceCode bash"><code class="sourceCode bash"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="ex">conda</span> create <span class="at">-n</span> deepseek_env python=3.8  </span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="ex">conda</span> activate deepseek_env  </span></code></pre></div></li>
</ul></li>
<li><strong>Install Required Packages</strong>:
<ul>
<li><p>Now, let’s install some important libraries and tools:</p>
<div class="sourceCode" id="cb2"><pre
class="sourceCode bash"><code class="sourceCode bash"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="ex">conda</span> install numpy pandas matplotlib seaborn  </span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="ex">conda</span> install <span class="at">-c</span> conda-forge tensorflow-gpu <span class="co"># This is for GPU support  </span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="ex">conda</span> install <span class="at">-c</span> conda-forge keras  </span></code></pre></div></li>
</ul></li>
<li><strong>Set Up CUDA and cuDNN</strong>:
<ul>
<li>We need to check that CUDA toolkit and cuDNN are installed right.
This helps TensorFlow use GPU power. We can follow the guide from the <a
href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html">NVIDIA
website</a>.</li>
</ul></li>
<li><strong>Clone DeepSeek Repository</strong>:
<ul>
<li><p>Next, we clone the DeepSeek repository from GitHub:</p>
<div class="sourceCode" id="cb3"><pre
class="sourceCode bash"><code class="sourceCode bash"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="fu">git</span> clone https://github.com/your-repo/DeepSeek.git  </span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="bu">cd</span> DeepSeek  </span></code></pre></div></li>
</ul></li>
<li><strong>Install Additional Dependencies</strong>:
<ul>
<li><p>Go to the folder we just cloned and install more
dependencies:</p>
<div class="sourceCode" id="cb4"><pre
class="sourceCode bash"><code class="sourceCode bash"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="ex">pip</span> install <span class="at">-r</span> requirements.txt  </span></code></pre></div></li>
</ul></li>
<li><strong>Verify Installation</strong>:
<ul>
<li><p>Finally, we check if TensorFlow can see the GPU:</p>
<div class="sourceCode" id="cb5"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> tensorflow <span class="im">as</span> tf  </span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Num GPUs Available: &quot;</span>, <span class="bu">len</span>(tf.config.list_physical_devices(<span class="st">&#39;GPU&#39;</span>)))  </span></code></pre></div></li>
</ul></li>
</ol>
<p>By doing these steps, we will have a local environment ready to train
DeepSeek well. We should check the official documentation for any
special settings for our computer. If we want to learn more about
generative models, we can read this article on <a
href="https://bestonlinetutorial.com/generative_ai/how-do-neural-networks-fuel-the-capabilities-of-generative-ai.html">how
neural networks fuel the capabilities of generative AI</a>.</p>
<h2
id="installing-required-dependencies-for-deepseek-local-training">Installing
Required Dependencies for DeepSeek Local Training</h2>
<p>To train and run DeepSeek locally, we need to install some
dependencies. Here is a simple step-by-step guide to help us get
everything ready.</p>
<ol type="1">
<li><p><strong>Python</strong>: First, we need to have Python 3.7 or
higher. We can download it from the <a
href="https://www.python.org/downloads/">official Python
website</a>.</p></li>
<li><p><strong>Create a Virtual Environment</strong>:</p>
<div class="sourceCode" id="cb6"><pre
class="sourceCode bash"><code class="sourceCode bash"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="ex">python</span> <span class="at">-m</span> venv deepseek-env</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="bu">source</span> deepseek-env/bin/activate  <span class="co"># If we use Windows, we write `deepseek-env\Scripts\activate`</span></span></code></pre></div></li>
<li><p><strong>Install Required Packages</strong>: Next, we install the
needed Python packages using pip. We might need to change the versions
based on what works well with DeepSeek.</p>
<div class="sourceCode" id="cb7"><pre
class="sourceCode bash"><code class="sourceCode bash"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="ex">pip</span> install numpy pandas tensorflow keras matplotlib scikit-learn</span></code></pre></div></li>
<li><p><strong>Install Additional Libraries</strong>: Depending on what
we want to do, we might need extra libraries like:</p>
<div class="sourceCode" id="cb8"><pre
class="sourceCode bash"><code class="sourceCode bash"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="ex">pip</span> install opencv-python pillow</span></code></pre></div></li>
<li><p><strong>Install DeepSeek</strong>: If DeepSeek is available as a
package, we can install it directly with pip:</p>
<div class="sourceCode" id="cb9"><pre
class="sourceCode bash"><code class="sourceCode bash"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="ex">pip</span> install deepseek</span></code></pre></div></li>
<li><p><strong>Verify Installation</strong>: We should check if
everything installed correctly:</p>
<div class="sourceCode" id="cb10"><pre
class="sourceCode bash"><code class="sourceCode bash"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="ex">python</span> <span class="at">-c</span> <span class="st">&quot;import numpy, pandas, tensorflow, keras, matplotlib, sklearn; print(&#39;All packages imported successfully&#39;)&quot;</span></span></code></pre></div></li>
</ol>
<p>We should also look at the official <a
href="https://github.com/your-repo/deepseek">DeepSeek documentation</a>
for any specific version needs or other dependencies that can help us
perform better.</p>
<p>For more information about generative AI models and how to train
them, we can read about <a
href="https://bestonlinetutorial.com/generative_ai/how-can-you-train-a-gan-a-step-by-step-tutorial-guide.html">how
to effectively train a GAN</a>.</p>
<h2 id="configuring-deepseek-for-local-training">Configuring DeepSeek
for Local Training</h2>
<p>To configure DeepSeek for local training, we need to change some
settings in the configuration file. This helps to improve the model’s
performance for our dataset and hardware.</p>
<ol type="1">
<li><p><strong>Locate the Configuration File</strong>:<br />
The configuration file is usually called <code>config.yaml</code> or
<code>deepseek_config.json</code>. It depends on the version we are
using. We can find it in the main folder of the DeepSeek
project.</p></li>
<li><p><strong>Edit Hyperparameters</strong>:<br />
We open the configuration file and change the hyperparameters to fit our
needs. Here is an example of what it might look like:</p>
<div class="sourceCode" id="cb11"><pre
class="sourceCode yaml"><code class="sourceCode yaml"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="fu">model</span><span class="kw">:</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="at">  </span><span class="fu">type</span><span class="kw">:</span><span class="at"> </span><span class="st">&quot;DeepSeek&quot;</span></span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a><span class="at">  </span><span class="fu">layers</span><span class="kw">:</span><span class="at"> </span><span class="dv">4</span></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a><span class="at">  </span><span class="fu">units</span><span class="kw">:</span><span class="at"> </span><span class="dv">256</span></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a><span class="at">  </span><span class="fu">activation</span><span class="kw">:</span><span class="at"> </span><span class="st">&quot;relu&quot;</span></span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a><span class="at">  </span><span class="fu">dropout_rate</span><span class="kw">:</span><span class="at"> </span><span class="fl">0.3</span></span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a><span class="fu">training</span><span class="kw">:</span></span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a><span class="at">  </span><span class="fu">batch_size</span><span class="kw">:</span><span class="at"> </span><span class="dv">32</span></span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a><span class="at">  </span><span class="fu">epochs</span><span class="kw">:</span><span class="at"> </span><span class="dv">100</span></span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a><span class="at">  </span><span class="fu">learning_rate</span><span class="kw">:</span><span class="at"> </span><span class="fl">0.001</span></span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a><span class="at">  </span><span class="fu">optimizer</span><span class="kw">:</span><span class="at"> </span><span class="st">&quot;adam&quot;</span></span></code></pre></div></li>
<li><p><strong>Specify Dataset Paths</strong>:<br />
We need to make sure we set the right paths for our training and
validation datasets. For example:</p>
<div class="sourceCode" id="cb12"><pre
class="sourceCode yaml"><code class="sourceCode yaml"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="fu">dataset</span><span class="kw">:</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="at">  </span><span class="fu">train</span><span class="kw">:</span><span class="at"> </span><span class="st">&quot;/path/to/your/train_data&quot;</span></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a><span class="at">  </span><span class="fu">validation</span><span class="kw">:</span><span class="at"> </span><span class="st">&quot;/path/to/your/validation_data&quot;</span></span></code></pre></div></li>
<li><p><strong>Set Device Configuration</strong>:<br />
If we use a GPU, we set the device settings. We can do this in the
configuration file or through environment variables. Here is an example
for CUDA:</p>
<div class="sourceCode" id="cb13"><pre
class="sourceCode yaml"><code class="sourceCode yaml"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="fu">device</span><span class="kw">:</span><span class="at"> </span><span class="st">&quot;cuda&quot;</span><span class="co">  # or &quot;cpu&quot; if we do not have a GPU</span></span></code></pre></div></li>
<li><p><strong>Logging and Checkpoints</strong>:<br />
We should update logging and checkpoint settings to track the training
process better:</p>
<div class="sourceCode" id="cb14"><pre
class="sourceCode yaml"><code class="sourceCode yaml"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="fu">logging</span><span class="kw">:</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="at">  </span><span class="fu">level</span><span class="kw">:</span><span class="at"> </span><span class="st">&quot;info&quot;</span></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a><span class="at">  </span><span class="fu">save_path</span><span class="kw">:</span><span class="at"> </span><span class="st">&quot;/path/to/save/checkpoints&quot;</span></span></code></pre></div></li>
<li><p><strong>Additional Parameters</strong>:<br />
Depending on what DeepSeek can do, we may need to set more parameters.
This can include early stopping and how often to save the model:</p>
<div class="sourceCode" id="cb15"><pre
class="sourceCode yaml"><code class="sourceCode yaml"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="fu">early_stopping</span><span class="kw">:</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="at">  </span><span class="fu">patience</span><span class="kw">:</span><span class="at"> </span><span class="dv">10</span></span></code></pre></div></li>
</ol>
<p>After we save the configuration file, we need to check that all paths
and parameters are correct. This way, we avoid problems during training.
This setup will make sure that DeepSeek is ready for local training and
can use our hardware well. For more information about generative AI
models, we can look at <a
href="https://bestonlinetutorial.com/generative_ai/what-are-the-key-differences-between-generative-and-discriminative-models-understanding-their-unique-features-and-applications.html">the
key differences between generative and discriminative models</a>.</p>
<h2 id="preparing-your-dataset-for-deepseek-local-training">Preparing
Your Dataset for DeepSeek Local Training</h2>
<p>To train DeepSeek on your computer, we need to get our dataset ready
in a way that the model can understand. Here are the main steps to
prepare our dataset:</p>
<ol type="1">
<li><p><strong>Data Collection</strong>: First, we gather data that is
important for our training goal. This data can be images, text, or other
types that DeepSeek can work with.</p></li>
<li><p><strong>Data Format</strong>: Next, we must make sure our data is
in the right format. DeepSeek usually needs structured data. For
example, if we use images, they should be in a folder structure that
DeepSeek can read.</p>
<pre class="plaintext"><code>dataset/
├── class1/
│   ├── image1.jpg
│   ├── image2.jpg
└── class2/
    ├── image1.jpg
    ├── image2.jpg</code></pre></li>
<li><p><strong>Data Labeling</strong>: For supervised training, we need
to label our data correctly. The labels should match the classes in our
dataset. We can use CSV or JSON format for annotations.</p>
<p>Example CSV format:</p>
<pre class="csv"><code>image_path,label
class1/image1.jpg,class1
class2/image1.jpg,class2</code></pre></li>
<li><p><strong>Data Preprocessing</strong>: We must normalize and
preprocess our data if needed. This can mean resizing images, tokenizing
text, or scaling numbers. We can use libraries like OpenCV or PIL to
process images.</p>
<p>Example code for resizing images using Python:</p>
<div class="sourceCode" id="cb18"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> PIL <span class="im">import</span> Image</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> resize_images(input_folder, output_folder, size<span class="op">=</span>(<span class="dv">128</span>, <span class="dv">128</span>)):</span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>    os.makedirs(output_folder, exist_ok<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> filename <span class="kw">in</span> os.listdir(input_folder):</span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> filename.endswith(<span class="st">&quot;.jpg&quot;</span>):</span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a>            img <span class="op">=</span> Image.<span class="bu">open</span>(os.path.join(input_folder, filename))</span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a>            img <span class="op">=</span> img.resize(size)</span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a>            img.save(os.path.join(output_folder, filename))</span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a>resize_images(<span class="st">&#39;dataset/class1&#39;</span>, <span class="st">&#39;dataset/resized/class1&#39;</span>)</span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a>resize_images(<span class="st">&#39;dataset/class2&#39;</span>, <span class="st">&#39;dataset/resized/class2&#39;</span>)</span></code></pre></div></li>
<li><p><strong>Data Splitting</strong>: We should split our dataset into
training, validation, and test sets. A common way to split is 70% for
training, 15% for validation, and 15% for testing.</p>
<p>Example code for splitting using scikit-learn:</p>
<div class="sourceCode" id="cb19"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> pd.read_csv(<span class="st">&#39;data_labels.csv&#39;</span>)</span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>train_data, test_data <span class="op">=</span> train_test_split(data, test_size<span class="op">=</span><span class="fl">0.3</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>val_data, test_data <span class="op">=</span> train_test_split(test_data, test_size<span class="op">=</span><span class="fl">0.5</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a>train_data.to_csv(<span class="st">&#39;train_labels.csv&#39;</span>, index<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a>val_data.to_csv(<span class="st">&#39;val_labels.csv&#39;</span>, index<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a>test_data.to_csv(<span class="st">&#39;test_labels.csv&#39;</span>, index<span class="op">=</span><span class="va">False</span>)</span></code></pre></div></li>
<li><p><strong>Data Augmentation</strong>: If we want, we can use data
augmentation techniques to make our training set more diverse. We can
use libraries like <code>imgaug</code> or <code>albumentations</code>
for image data.</p></li>
<li><p><strong>Data Loading</strong>: Finally, we need to create data
loaders that work with DeepSeek. We can use frameworks like TensorFlow
or PyTorch for this.</p>
<p>Example PyTorch DataLoader setup:</p>
<div class="sourceCode" id="cb20"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchvision <span class="im">import</span> datasets, transforms</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> DataLoader</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a>transform <span class="op">=</span> transforms.Compose([</span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>    transforms.Resize((<span class="dv">128</span>, <span class="dv">128</span>)),</span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>    transforms.ToTensor(),</span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a>train_dataset <span class="op">=</span> datasets.ImageFolder(root<span class="op">=</span><span class="st">&#39;dataset/resized&#39;</span>, transform<span class="op">=</span>transform)</span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a>train_loader <span class="op">=</span> DataLoader(train_dataset, batch_size<span class="op">=</span><span class="dv">32</span>, shuffle<span class="op">=</span><span class="va">True</span>)</span></code></pre></div></li>
</ol>
<p>We need to make sure our dataset is ready for the best performance
when we train DeepSeek on our computer. Good preparation of the dataset
is very important for successful model training.</p>
<h2 id="training-deepseek-locally-step-by-step">Training DeepSeek
Locally Step by Step</h2>
<p>To train DeepSeek locally, we can follow these simple steps. This
will help us have a smooth and good training process.</p>
<ol type="1">
<li><p><strong>Clone the DeepSeek Repository</strong></p>
<p>First, we need to clone the DeepSeek repository from GitHub. We can
do this with:</p>
<div class="sourceCode" id="cb21"><pre
class="sourceCode bash"><code class="sourceCode bash"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="fu">git</span> clone https://github.com/username/deepseek.git</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a><span class="bu">cd</span> deepseek</span></code></pre></div></li>
<li><p><strong>Set Up a Virtual Environment</strong></p>
<p>It is a good idea to use a virtual environment for our project. We
can set it up with:</p>
<div class="sourceCode" id="cb22"><pre
class="sourceCode bash"><code class="sourceCode bash"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="ex">python</span> <span class="at">-m</span> venv venv</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a><span class="bu">source</span> venv/bin/activate  <span class="co"># For Linux/Mac</span></span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a><span class="ex">venv\Scripts\activate</span>  <span class="co"># For Windows</span></span></code></pre></div></li>
<li><p><strong>Install Required Dependencies</strong></p>
<p>Next, we install the libraries and dependencies from
<code>requirements.txt</code>. We can use:</p>
<div class="sourceCode" id="cb23"><pre
class="sourceCode bash"><code class="sourceCode bash"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="ex">pip</span> install <span class="at">-r</span> requirements.txt</span></code></pre></div></li>
<li><p><strong>Configure DeepSeek Settings</strong></p>
<p>We should change the configuration file <code>config.yaml</code>
based on our dataset and training needs. The important settings are:</p>
<div class="sourceCode" id="cb24"><pre
class="sourceCode yaml"><code class="sourceCode yaml"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="fu">model</span><span class="kw">:</span></span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a><span class="at">  </span><span class="fu">type</span><span class="kw">:</span><span class="at"> </span><span class="st">&quot;DeepSeek&quot;</span></span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a><span class="at">  </span><span class="fu">epochs</span><span class="kw">:</span><span class="at"> </span><span class="dv">100</span></span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a><span class="at">  </span><span class="fu">batch_size</span><span class="kw">:</span><span class="at"> </span><span class="dv">32</span></span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a><span class="at">  </span><span class="fu">learning_rate</span><span class="kw">:</span><span class="at"> </span><span class="fl">0.001</span></span></code></pre></div></li>
<li><p><strong>Prepare Your Dataset</strong></p>
<p>Make sure our dataset is in the right format. We should put our
training data in the <code>data</code> folder. A usual structure looks
like this:</p>
<pre><code>/data
  /train
    - image1.jpg
    - image2.jpg
  /test
    - image3.jpg
    - image4.jpg</code></pre></li>
<li><p><strong>Launch Training</strong></p>
<p>Now, we can use the training script to start the training. We
run:</p>
<div class="sourceCode" id="cb26"><pre
class="sourceCode bash"><code class="sourceCode bash"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="ex">python</span> train.py <span class="at">--config</span> config.yaml</span></code></pre></div>
<p>We should keep an eye on the output for any problems. This way we can
see if the training is going well.</p></li>
<li><p><strong>Save the Model</strong></p>
<p>After we finish training, we need to save the model weights. Usually,
the training script does this. But we can save it like this if we
want:</p>
<div class="sourceCode" id="cb27"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>model.save_weights(<span class="st">&#39;deepseek_model.h5&#39;</span>)</span></code></pre></div></li>
<li><p><strong>Validate the Model</strong></p>
<p>After training, we should check the model using a different
validation script. We do it like this:</p>
<div class="sourceCode" id="cb28"><pre
class="sourceCode bash"><code class="sourceCode bash"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="ex">python</span> validate.py <span class="at">--config</span> config.yaml <span class="at">--weights</span> deepseek_model.h5</span></code></pre></div>
<p>We should look at the accuracy and loss metrics to see how well the
model is performing.</p></li>
<li><p><strong>Optimize Hyperparameters (Optional)</strong></p>
<p>If we are not happy with how the model performs, we can change the
hyperparameters in <code>config.yaml</code> and train again.</p></li>
</ol>
<p>By following these steps, we can train DeepSeek locally. This will
help us to optimize our model. For more tips on training generative
models, we can check out <a
href="https://bestonlinetutorial.com/generative_ai/how-can-you-train-a-gan-a-step-by-step-tutorial-guide.html">how
to train a GAN</a>.</p>
<h2 id="validating-your-deepseek-model-after-local-training">Validating
Your DeepSeek Model After Local Training</h2>
<p>After we train our DeepSeek model locally, we need to check how well
it performs. This is important to see if it meets our needs. Validation
shows us if the model has learned too much from the training data or if
it works well on new data we have not seen before.</p>
<h3 id="steps-for-validation">Steps for Validation</h3>
<ol type="1">
<li><p><strong>Split Your Dataset</strong>: We should have a separate
validation set. This set should not be used during training. A common
split is 70-30 or 80-20 for training and validation datasets.</p></li>
<li><p><strong>Load the Validation Dataset</strong>: We can use a data
loader to load our validation dataset. Here is an example in Python:</p>
<div class="sourceCode" id="cb29"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchvision <span class="im">import</span> datasets, transforms</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a>validation_transform <span class="op">=</span> transforms.Compose([</span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a>    transforms.Resize((<span class="dv">224</span>, <span class="dv">224</span>)),</span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a>    transforms.ToTensor(),</span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb29-8"><a href="#cb29-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-9"><a href="#cb29-9" aria-hidden="true" tabindex="-1"></a>validation_dataset <span class="op">=</span> datasets.ImageFolder(root<span class="op">=</span><span class="st">&#39;path/to/validation/data&#39;</span>, transform<span class="op">=</span>validation_transform)</span>
<span id="cb29-10"><a href="#cb29-10" aria-hidden="true" tabindex="-1"></a>validation_loader <span class="op">=</span> torch.utils.data.DataLoader(validation_dataset, batch_size<span class="op">=</span><span class="dv">32</span>, shuffle<span class="op">=</span><span class="va">False</span>)</span></code></pre></div></li>
<li><p><strong>Evaluate the Model</strong>: We can use the validation
dataset to check how well our DeepSeek model performs. Below is an
example code snippet:</p>
<div class="sourceCode" id="cb30"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">eval</span>()  <span class="co"># Set the model to evaluation mode</span></span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>total_correct <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a>total_samples <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad():</span>
<span id="cb30-6"><a href="#cb30-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> images, labels <span class="kw">in</span> validation_loader:</span>
<span id="cb30-7"><a href="#cb30-7" aria-hidden="true" tabindex="-1"></a>        outputs <span class="op">=</span> model(images)</span>
<span id="cb30-8"><a href="#cb30-8" aria-hidden="true" tabindex="-1"></a>        _, predicted <span class="op">=</span> torch.<span class="bu">max</span>(outputs.data, <span class="dv">1</span>)</span>
<span id="cb30-9"><a href="#cb30-9" aria-hidden="true" tabindex="-1"></a>        total_samples <span class="op">+=</span> labels.size(<span class="dv">0</span>)</span>
<span id="cb30-10"><a href="#cb30-10" aria-hidden="true" tabindex="-1"></a>        total_correct <span class="op">+=</span> (predicted <span class="op">==</span> labels).<span class="bu">sum</span>().item()</span>
<span id="cb30-11"><a href="#cb30-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-12"><a href="#cb30-12" aria-hidden="true" tabindex="-1"></a>accuracy <span class="op">=</span> total_correct <span class="op">/</span> total_samples</span>
<span id="cb30-13"><a href="#cb30-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&#39;Validation Accuracy: </span><span class="sc">{</span>accuracy <span class="op">*</span> <span class="dv">100</span><span class="sc">:.2f}</span><span class="ss">%&#39;</span>)</span></code></pre></div></li>
<li><p><strong>Calculate Additional Metrics</strong>: Besides accuracy,
we can calculate other things like precision, recall, and F1-score. This
gives us a better view of how our model is doing. We can use libraries
like <code>scikit-learn</code> for this:</p>
<div class="sourceCode" id="cb31"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> classification_report</span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a>all_labels <span class="op">=</span> []</span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a>all_predictions <span class="op">=</span> []</span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad():</span>
<span id="cb31-7"><a href="#cb31-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> images, labels <span class="kw">in</span> validation_loader:</span>
<span id="cb31-8"><a href="#cb31-8" aria-hidden="true" tabindex="-1"></a>        outputs <span class="op">=</span> model(images)</span>
<span id="cb31-9"><a href="#cb31-9" aria-hidden="true" tabindex="-1"></a>        _, predicted <span class="op">=</span> torch.<span class="bu">max</span>(outputs.data, <span class="dv">1</span>)</span>
<span id="cb31-10"><a href="#cb31-10" aria-hidden="true" tabindex="-1"></a>        all_labels.extend(labels.numpy())</span>
<span id="cb31-11"><a href="#cb31-11" aria-hidden="true" tabindex="-1"></a>        all_predictions.extend(predicted.numpy())</span>
<span id="cb31-12"><a href="#cb31-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-13"><a href="#cb31-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(classification_report(all_labels, all_predictions))</span></code></pre></div></li>
<li><p><strong>Visualize Results</strong>: We can use tools to show
confusion matrices or ROC curves. This helps us understand how our model
is performing better.</p>
<div class="sourceCode" id="cb32"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> confusion_matrix</span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a>cm <span class="op">=</span> confusion_matrix(all_labels, all_predictions)</span>
<span id="cb32-6"><a href="#cb32-6" aria-hidden="true" tabindex="-1"></a>sns.heatmap(cm, annot<span class="op">=</span><span class="va">True</span>, fmt<span class="op">=</span><span class="st">&#39;d&#39;</span>, cmap<span class="op">=</span><span class="st">&#39;Blues&#39;</span>)</span>
<span id="cb32-7"><a href="#cb32-7" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&#39;Predicted&#39;</span>)</span>
<span id="cb32-8"><a href="#cb32-8" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;True&#39;</span>)</span>
<span id="cb32-9"><a href="#cb32-9" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&#39;Confusion Matrix&#39;</span>)</span>
<span id="cb32-10"><a href="#cb32-10" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div></li>
</ol>
<p>By following these steps, we can check our DeepSeek model after local
training. This helps us make sure it is ready for use. For more
information on model evaluation, we can look at <a
href="https://bestonlinetutorial.com/generative_ai/what-are-the-real-life-applications-of-generative-ai.html">the
real-life applications of generative AI</a>.</p>
<h2 id="running-deepseek-locally-for-inference">Running DeepSeek Locally
for Inference</h2>
<p>To run DeepSeek locally for inference, we need to make sure our model
is trained and saved correctly. Here are the steps to load our trained
model and use it on new data.</p>
<ol type="1">
<li><p><strong>Load the Trained Model:</strong> We have to load the
model from the saved checkpoint. We can do this with the right library
like TensorFlow or PyTorch.</p>
<div class="sourceCode" id="cb33"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> deepseek <span class="im">import</span> DeepSeekModel</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the model</span></span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> DeepSeekModel.load_from_checkpoint(<span class="st">&#39;path/to/your/model_checkpoint.ckpt&#39;</span>)</span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">eval</span>()  <span class="co"># Set the model to evaluation mode</span></span></code></pre></div></li>
<li><p><strong>Prepare the Input Data:</strong> We must preprocess the
input data just like we did for the training data. This may mean we
resize it, normalize it, or tokenize it.</p>
<div class="sourceCode" id="cb34"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchvision <span class="im">import</span> transforms</span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> PIL <span class="im">import</span> Image</span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the transformation</span></span>
<span id="cb34-5"><a href="#cb34-5" aria-hidden="true" tabindex="-1"></a>transform <span class="op">=</span> transforms.Compose([</span>
<span id="cb34-6"><a href="#cb34-6" aria-hidden="true" tabindex="-1"></a>    transforms.Resize((<span class="dv">224</span>, <span class="dv">224</span>)),</span>
<span id="cb34-7"><a href="#cb34-7" aria-hidden="true" tabindex="-1"></a>    transforms.ToTensor(),</span>
<span id="cb34-8"><a href="#cb34-8" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb34-9"><a href="#cb34-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-10"><a href="#cb34-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Load your image</span></span>
<span id="cb34-11"><a href="#cb34-11" aria-hidden="true" tabindex="-1"></a>img <span class="op">=</span> Image.<span class="bu">open</span>(<span class="st">&#39;path/to/your/image.jpg&#39;</span>)</span>
<span id="cb34-12"><a href="#cb34-12" aria-hidden="true" tabindex="-1"></a>img_tensor <span class="op">=</span> transform(img).unsqueeze(<span class="dv">0</span>)  <span class="co"># Add batch dimension</span></span></code></pre></div></li>
<li><p><strong>Perform Inference:</strong> Now we can pass the prepared
input data through the model to get our predictions.</p>
<div class="sourceCode" id="cb35"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad():  <span class="co"># No need to calculate gradients</span></span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a>    predictions <span class="op">=</span> model(img_tensor)</span></code></pre></div></li>
<li><p><strong>Process the Output:</strong> We might need to process the
model’s output to understand the results better.</p>
<div class="sourceCode" id="cb36"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Assuming the model output is a class score</span></span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a>predicted_class <span class="op">=</span> predictions.argmax(dim<span class="op">=</span><span class="dv">1</span>).item()</span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&#39;Predicted Class: </span><span class="sc">{</span>predicted_class<span class="sc">}</span><span class="ss">&#39;</span>)</span></code></pre></div></li>
<li><p><strong>Batch Inference (Optional):</strong> If we have many data
points, we can do batch inference by stacking the tensors.</p>
<div class="sourceCode" id="cb37"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Assuming img_tensors is a list of input tensors</span></span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a>batch_tensor <span class="op">=</span> torch.stack(img_tensors)</span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-4"><a href="#cb37-4" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad():</span>
<span id="cb37-5"><a href="#cb37-5" aria-hidden="true" tabindex="-1"></a>    batch_predictions <span class="op">=</span> model(batch_tensor)</span></code></pre></div></li>
<li><p><strong>Visualize Results (Optional):</strong> If we want, we can
visualize the predictions with the input data.</p>
<div class="sourceCode" id="cb38"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a>plt.imshow(img)</span>
<span id="cb38-4"><a href="#cb38-4" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="ss">f&#39;Predicted Class: </span><span class="sc">{</span>predicted_class<span class="sc">}</span><span class="ss">&#39;</span>)</span>
<span id="cb38-5"><a href="#cb38-5" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div></li>
</ol>
<p>By following these steps, we can run DeepSeek locally for inference.
This helps us use our trained model for different applications. For more
information about generative AI and model training, we can check out <a
href="https://bestonlinetutorial.com/generative_ai/what-is-generative-ai-and-how-does-it-work-a-comprehensive-guide.html">what
generative AI is and how it works</a>.</p>
<h2 id="practical-examples-of-using-deepseek-locally">Practical Examples
of Using DeepSeek Locally</h2>
<p>We can use DeepSeek locally in many ways. Here are some easy examples
that show what it can do in different situations.</p>
<h3 id="example-1-text-generation">Example 1: Text Generation</h3>
<p>This example shows how we can use DeepSeek to create text from a
given prompt.</p>
<div class="sourceCode" id="cb39"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> deepseek <span class="im">import</span> DeepSeek</span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Start DeepSeek model</span></span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> DeepSeek(model_type<span class="op">=</span><span class="st">&#39;text&#39;</span>)</span>
<span id="cb39-5"><a href="#cb39-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-6"><a href="#cb39-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Give a prompt for text generation</span></span>
<span id="cb39-7"><a href="#cb39-7" aria-hidden="true" tabindex="-1"></a>prompt <span class="op">=</span> <span class="st">&quot;In the future, artificial intelligence will&quot;</span></span>
<span id="cb39-8"><a href="#cb39-8" aria-hidden="true" tabindex="-1"></a>generated_text <span class="op">=</span> model.generate(prompt)</span>
<span id="cb39-9"><a href="#cb39-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-10"><a href="#cb39-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Generated Text:&quot;</span>, generated_text)</span></code></pre></div>
<h3 id="example-2-image-generation">Example 2: Image Generation</h3>
<p>In this example, we use DeepSeek to make images from random
noise.</p>
<div class="sourceCode" id="cb40"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> deepseek <span class="im">import</span> DeepSeek</span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Start DeepSeek model for image generation</span></span>
<span id="cb40-4"><a href="#cb40-4" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> DeepSeek(model_type<span class="op">=</span><span class="st">&#39;image&#39;</span>)</span>
<span id="cb40-5"><a href="#cb40-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-6"><a href="#cb40-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Create an image</span></span>
<span id="cb40-7"><a href="#cb40-7" aria-hidden="true" tabindex="-1"></a>generated_image <span class="op">=</span> model.generate_image()</span>
<span id="cb40-8"><a href="#cb40-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-9"><a href="#cb40-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Save or show the image</span></span>
<span id="cb40-10"><a href="#cb40-10" aria-hidden="true" tabindex="-1"></a>generated_image.save(<span class="st">&#39;generated_image.png&#39;</span>)</span></code></pre></div>
<h3 id="example-3-fine-tuning-a-pre-trained-model">Example 3:
Fine-Tuning a Pre-trained Model</h3>
<p>We can improve the performance of a DeepSeek model by fine-tuning it
on our own data.</p>
<div class="sourceCode" id="cb41"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> deepseek <span class="im">import</span> DeepSeek</span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Start DeepSeek with a pre-trained model</span></span>
<span id="cb41-4"><a href="#cb41-4" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> DeepSeek(model_type<span class="op">=</span><span class="st">&#39;text&#39;</span>, pretrained<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb41-5"><a href="#cb41-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-6"><a href="#cb41-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Load our dataset</span></span>
<span id="cb41-7"><a href="#cb41-7" aria-hidden="true" tabindex="-1"></a>train_data <span class="op">=</span> model.load_data(<span class="st">&#39;path/to/your/dataset&#39;</span>)</span>
<span id="cb41-8"><a href="#cb41-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-9"><a href="#cb41-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Fine-tune the model</span></span>
<span id="cb41-10"><a href="#cb41-10" aria-hidden="true" tabindex="-1"></a>model.train(train_data, epochs<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb41-11"><a href="#cb41-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-12"><a href="#cb41-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Save the fine-tuned model</span></span>
<span id="cb41-13"><a href="#cb41-13" aria-hidden="true" tabindex="-1"></a>model.save(<span class="st">&#39;fine_tuned_model&#39;</span>)</span></code></pre></div>
<h3 id="example-4-running-inference-on-a-custom-dataset">Example 4:
Running Inference on a Custom Dataset</h3>
<p>After training, we can run inference with our own dataset.</p>
<div class="sourceCode" id="cb42"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> deepseek <span class="im">import</span> DeepSeek</span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the fine-tuned model</span></span>
<span id="cb42-4"><a href="#cb42-4" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> DeepSeek(model_path<span class="op">=</span><span class="st">&#39;fine_tuned_model&#39;</span>)</span>
<span id="cb42-5"><a href="#cb42-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-6"><a href="#cb42-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Prepare input for inference</span></span>
<span id="cb42-7"><a href="#cb42-7" aria-hidden="true" tabindex="-1"></a>input_data <span class="op">=</span> [<span class="st">&quot;Example input text to analyze&quot;</span>]</span>
<span id="cb42-8"><a href="#cb42-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-9"><a href="#cb42-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Get predictions</span></span>
<span id="cb42-10"><a href="#cb42-10" aria-hidden="true" tabindex="-1"></a>predictions <span class="op">=</span> model.predict(input_data)</span>
<span id="cb42-11"><a href="#cb42-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-12"><a href="#cb42-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Predictions:&quot;</span>, predictions)</span></code></pre></div>
<h3 id="example-5-evaluating-model-performance">Example 5: Evaluating
Model Performance</h3>
<p>After we train and run inference, we need to check how well the model
performs.</p>
<div class="sourceCode" id="cb43"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> deepseek <span class="im">import</span> DeepSeek</span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the model</span></span>
<span id="cb43-4"><a href="#cb43-4" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> DeepSeek(model_path<span class="op">=</span><span class="st">&#39;fine_tuned_model&#39;</span>)</span>
<span id="cb43-5"><a href="#cb43-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-6"><a href="#cb43-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluate the model</span></span>
<span id="cb43-7"><a href="#cb43-7" aria-hidden="true" tabindex="-1"></a>evaluation_results <span class="op">=</span> model.evaluate(<span class="st">&#39;path/to/evaluation/data&#39;</span>)</span>
<span id="cb43-8"><a href="#cb43-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-9"><a href="#cb43-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Evaluation Results:&quot;</span>, evaluation_results)</span></code></pre></div>
<p>These examples show how we can train and run DeepSeek locally for
different uses. This includes text and image generation, fine-tuning
models, and running inference. For more insights on generative AI and
its uses, check out <a
href="https://bestonlinetutorial.com/generative_ai/what-are-the-real-life-applications-of-generative-ai.html">what
are the real-life applications of generative AI</a>.</p>
<h2 id="frequently-asked-questions">Frequently Asked Questions</h2>
<h3 id="what-is-deepseek-and-how-does-it-work-for-local-training">1.
What is DeepSeek and how does it work for local training?</h3>
<p>DeepSeek is a smart model made for deep learning. It works especially
well in generative AI. To train DeepSeek on your own computer, we need
to set up our environment with the right tools and settings. This helps
it run better on our machine. If we want to learn more about generative
AI, we can read this <a
href="https://bestonlinetutorial.com/generative_ai/what-is-generative-ai-and-how-does-it-work-a-comprehensive-guide.html">guide
on generative AI</a>.</p>
<h3 id="what-are-the-hardware-requirements-to-train-deepseek-locally">2.
What are the hardware requirements to train DeepSeek locally?</h3>
<p>To train DeepSeek on our machine, we should have a strong GPU. It is
best if it has at least 8GB of VRAM. This helps handle the work we need
to do. We also need a multi-core CPU and at least 16GB RAM. This will
help our data processing go smoothly. If our system meets these needs,
we will have a better training experience.</p>
<h3 id="how-can-i-prepare-my-dataset-for-deepseek-local-training">3. How
can I prepare my dataset for DeepSeek local training?</h3>
<p>To get our dataset ready for DeepSeek training, we must organize it
in a way that works with the model. We can use formats like CSV or JSON.
It is also important to label our data correctly. We should clean and
normalize our data to help the model work better. For more steps, we can
check this <a
href="https://bestonlinetutorial.com/generative_ai/how-can-you-train-a-gan-a-step-by-step-tutorial-guide.html">step-by-step
guide on training generative models</a>.</p>
<h3
id="what-dependencies-do-i-need-to-install-for-deepseek-local-training">4.
What dependencies do I need to install for DeepSeek local training?</h3>
<p>To train DeepSeek locally, we need to install Python and some
libraries. These include TensorFlow or PyTorch, NumPy, and pandas. It
might be good to use virtual environments. This helps us manage these
tools better. We can read this article about <a
href="https://bestonlinetutorial.com/generative_ai/how-can-you-effectively-use-transformers-for-text-generation.html">using
transformers for text generation</a> if we want to learn how to use
specific frameworks like TensorFlow.</p>
<h3 id="how-do-i-validate-my-deepseek-model-after-local-training">5. How
do I validate my DeepSeek model after local training?</h3>
<p>After we train our DeepSeek model, we need to check how well it
works. We can do this by using a separate dataset for validation. This
helps us see how the model performs on new data. We should look at
important metrics like accuracy, precision, recall, and F1 score. This
way, we can make sure our model works well outside of the training data.
For more on model evaluations, we can read about <a
href="https://bestonlinetutorial.com/generative_ai/what-are-the-latest-generative-ai-models-and-their-use-cases-in-2023.html">the
latest generative AI models and their use cases</a>.</p>

                        </div>

                    </div>
                    <!--//container-->
                </article>

            </div>
            <!--//main-wrapper-->

            <div id="footer-placeholder"></div>

            <!-- Javascript -->
            <script src="/assets/plugins/popper.min.js" defer></script>
            <script src="/assets/plugins/bootstrap/js/bootstrap.min.js" defer></script>
            <script src="/assets/fontawesome/js/all.min.js" defer></script>
        </body>

        </html>
            
            